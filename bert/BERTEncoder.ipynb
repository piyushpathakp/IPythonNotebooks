{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729d1c9b943c43708cd9d01e3e7afcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79c41994ef645efac9b8aa3089efb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8f4b40558d45cd8a654c229841dcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'What the heck? Anyway, I do not care!', \n",
    "    'I am a British citizen.',\n",
    "    'He is the king of England.', \n",
    "    'He is the king of Python, a good machine learning engineer.',\n",
    "    'He is the king of Spain.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'the', 'heck', '?', 'anyway', ',', 'i', 'do', 'not', 'care', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Keyword arguments {'trunction': True} not recognized.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Keyword arguments {'trunction': True} not recognized.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Keyword arguments {'trunction': True} not recognized.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Keyword arguments {'trunction': True} not recognized.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Keyword arguments {'trunction': True} not recognized.\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "tokenized_texts = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    encoded_dict = \\\n",
    "        tokenizer.encode_plus(\n",
    "                         sentence,\n",
    "                         add_special_tokens=True,\n",
    "                         trunction=True,\n",
    "                         max_length=48,\n",
    "                         pad_to_max_length=True,\n",
    "                         return_tensors='pt')\n",
    "    \n",
    "    marked_text = '[CLS]' + sentence + '[SEP]'\n",
    "    tokenized_texts.append(tokenizer.tokenize(marked_text))\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2002, 2003, 1996, 2332, 1997, 3577, 1012,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  101,  2054,  1996, 17752,  1029,  4312,  1010,  1045,  2079,  2025,\n",
       "           2729,   999,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[ 101, 1045, 2572, 1037, 2329, 6926, 1012,  102,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[ 101, 2002, 2003, 1996, 2332, 1997, 2563, 1012,  102,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[  101,  2002,  2003,  1996,  2332,  1997, 18750,  1010,  1037,  2204,\n",
       "           3698,  4083,  3992,  1012,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[ 101, 2002, 2003, 1996, 2332, 1997, 3577, 1012,  102,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2054,  1996, 17752,  1029,  4312,  1010,  1045,  2079,  2025,\n",
       "          2729,   999,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1045,  2572,  1037,  2329,  6926,  1012,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2002,  2003,  1996,  2332,  1997,  2563,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2002,  2003,  1996,  2332,  1997, 18750,  1010,  1037,  2204,\n",
       "          3698,  4083,  3992,  1012,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2002,  2003,  1996,  2332,  1997,  3577,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_id = torch.ones_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1, vec2, hidden_state = model(input_ids, segments_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 48, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n"
     ]
    }
   ],
   "source": [
    "for vec in hidden_state:\n",
    "    print(vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3138,  0.2462,  0.5285,  ..., -0.2610,  0.6147, -0.5086],\n",
       "         [ 0.0167,  0.6089,  0.0182,  ...,  0.5430,  0.6684, -0.2759],\n",
       "         [-0.2177,  0.0715,  0.8959,  ...,  0.4597,  1.2163, -0.7695],\n",
       "         ...,\n",
       "         [ 0.3888, -0.3321,  0.8575,  ..., -0.7538, -0.0445, -1.1235],\n",
       "         [ 0.3560, -0.3697,  0.8404,  ..., -0.7706, -0.0429, -1.2014],\n",
       "         [ 0.3845, -0.3076,  0.7683,  ..., -0.6878, -0.0829, -1.4351]],\n",
       "\n",
       "        [[-0.5446,  0.3957,  0.4429,  ..., -0.4456,  0.5724, -0.4602],\n",
       "         [ 0.0259,  0.5068, -0.4471,  ..., -0.0314,  0.8646,  0.1357],\n",
       "         [ 0.1698,  0.7303, -0.1191,  ..., -0.3945,  0.9425, -0.0279],\n",
       "         ...,\n",
       "         [ 0.4271, -0.2452,  0.9051,  ..., -0.7676, -0.0622, -1.1299],\n",
       "         [ 0.4130, -0.2979,  0.8909,  ..., -0.7893, -0.0442, -1.1998],\n",
       "         [ 0.4956, -0.2175,  0.8230,  ..., -0.7031, -0.0845, -1.4285]],\n",
       "\n",
       "        [[-0.6090,  0.2783,  0.3233,  ..., -0.2305,  0.7675, -0.3901],\n",
       "         [-0.2373,  0.0380,  0.3182,  ..., -0.2880,  1.1886, -0.4050],\n",
       "         [-0.2734,  0.6602,  0.3248,  ..., -0.2998,  0.7575,  0.2746],\n",
       "         ...,\n",
       "         [ 0.3696, -0.2936,  0.9057,  ..., -0.7218, -0.0293, -1.1011],\n",
       "         [ 0.3430, -0.3504,  0.8852,  ..., -0.7431, -0.0200, -1.1733],\n",
       "         [ 0.4308, -0.2744,  0.8123,  ..., -0.6653, -0.0622, -1.4335]],\n",
       "\n",
       "        [[-0.6490,  0.1768,  0.1501,  ..., -0.0834,  0.8151, -0.4756],\n",
       "         [-0.5282, -0.0673, -0.5258,  ...,  0.1496,  1.2565, -0.7144],\n",
       "         [-0.2344,  0.3949, -0.1640,  ..., -0.3821,  0.6594,  0.4121],\n",
       "         ...,\n",
       "         [ 0.3719, -0.3113,  0.9232,  ..., -0.7549, -0.0534, -1.1242],\n",
       "         [ 0.3581, -0.3751,  0.9070,  ..., -0.7603, -0.0522, -1.2034],\n",
       "         [ 0.4308, -0.3179,  0.8064,  ..., -0.6843, -0.0869, -1.5022]],\n",
       "\n",
       "        [[-0.6653,  0.2582,  0.3288,  ..., -0.2145,  0.7753, -0.4071],\n",
       "         [-0.2967, -0.0064,  0.0579,  ..., -0.2400,  1.1697, -0.4805],\n",
       "         [-0.4015,  0.5438,  0.1952,  ..., -0.2082,  0.7234,  0.1354],\n",
       "         ...,\n",
       "         [ 0.3525, -0.2954,  0.9034,  ..., -0.6887, -0.0163, -1.0784],\n",
       "         [ 0.3255, -0.3524,  0.8837,  ..., -0.7063, -0.0062, -1.1512],\n",
       "         [ 0.4145, -0.2822,  0.8131,  ..., -0.6329, -0.0428, -1.4101]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6290, -0.5717, -0.9939,  ..., -0.9069, -0.6203,  0.6406],\n",
       "        [-0.5509, -0.6027, -0.9871,  ..., -0.8431, -0.6295,  0.5892],\n",
       "        [-0.4425, -0.5576, -0.9889,  ..., -0.8451, -0.5804,  0.3482],\n",
       "        [-0.4582, -0.5811, -0.9928,  ..., -0.8960, -0.5742,  0.2432],\n",
       "        [-0.4800, -0.5522, -0.9902,  ..., -0.8678, -0.6044,  0.3598]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 9.8677e-01,  4.5401e-01, -1.0180e+00,  ...,  7.5422e-01,\n",
       "            2.9288e-01, -1.5443e+00],\n",
       "          [-7.7901e-01,  4.7813e-01,  8.5864e-02,  ..., -2.4891e-01,\n",
       "            5.0784e-01, -5.6890e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]],\n",
       "\n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [-3.4022e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
       "            8.9008e-01,  1.6575e-01],\n",
       "          [-6.3496e-01,  1.9748e-01,  2.5116e-01,  ..., -4.0819e-02,\n",
       "            1.3468e+00, -6.9357e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]],\n",
       "\n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 5.4919e-03,  2.1535e-01,  2.6523e-01,  ...,  3.8705e-02,\n",
       "           -5.9142e-02,  2.8200e-01],\n",
       "          [-6.2703e-01, -6.3313e-02, -3.1428e-01,  ...,  3.4265e-01,\n",
       "            4.6361e-01,  4.5937e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]],\n",
       "\n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 5.4919e-03,  2.1535e-01,  2.6523e-01,  ...,  3.8705e-02,\n",
       "           -5.9142e-02,  2.8200e-01],\n",
       "          [-6.2703e-01, -6.3313e-02, -3.1428e-01,  ...,  3.4265e-01,\n",
       "            4.6361e-01,  4.5937e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]],\n",
       "\n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 5.4919e-03,  2.1535e-01,  2.6523e-01,  ...,  3.8705e-02,\n",
       "           -5.9142e-02,  2.8200e-01],\n",
       "          [-6.2703e-01, -6.3313e-02, -3.1428e-01,  ...,  3.4265e-01,\n",
       "            4.6361e-01,  4.5937e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1308e-01,  8.1617e-03, -1.3704e-01,  ...,  2.1580e-01,\n",
       "           -3.2235e-02, -1.3440e-02],\n",
       "          [ 9.0704e-01,  7.0520e-01, -1.6447e+00,  ...,  1.0943e+00,\n",
       "           -3.0130e-01, -1.7418e+00],\n",
       "          [-7.1098e-01,  1.3710e-01, -2.0280e-01,  ..., -4.7077e-01,\n",
       "            4.3523e-01, -1.0649e+00],\n",
       "          ...,\n",
       "          [ 3.0816e-01, -2.5008e-01, -6.4970e-02,  ...,  1.6541e-01,\n",
       "            3.1576e-02,  7.6767e-02],\n",
       "          [ 3.9516e-01, -4.2812e-01, -1.8181e-01,  ..., -8.8858e-03,\n",
       "            1.3801e-01,  9.6937e-02],\n",
       "          [ 5.7873e-01, -2.0464e-01, -2.1728e-01,  ..., -5.9887e-02,\n",
       "            1.0451e-02, -2.7139e-02]],\n",
       "\n",
       "         [[ 1.0899e-01, -3.3187e-02, -1.0779e-01,  ...,  2.3961e-01,\n",
       "           -5.2650e-02, -5.7180e-02],\n",
       "          [ 3.7829e-01, -1.8637e-01, -4.9956e-01,  ...,  6.6777e-01,\n",
       "            7.9297e-01, -1.6253e-01],\n",
       "          [-5.4013e-01, -4.0028e-01, -5.0542e-01,  ..., -3.1529e-02,\n",
       "            1.4579e+00, -8.8831e-01],\n",
       "          ...,\n",
       "          [ 3.0309e-01, -2.6873e-01, -4.2792e-02,  ...,  1.7498e-01,\n",
       "            2.6836e-02,  5.6603e-02],\n",
       "          [ 3.8686e-01, -4.4124e-01, -1.5079e-01,  ...,  8.6788e-03,\n",
       "            1.2877e-01,  7.2460e-02],\n",
       "          [ 5.6493e-01, -2.2068e-01, -1.9159e-01,  ..., -4.2235e-02,\n",
       "            5.9325e-03, -4.0980e-02]],\n",
       "\n",
       "         [[ 9.9148e-02,  1.4080e-02, -1.2773e-01,  ...,  2.0874e-01,\n",
       "           -3.2873e-02, -5.1309e-03],\n",
       "          [-3.3077e-01, -2.1296e-01, -1.2347e-03,  ..., -2.0647e-01,\n",
       "           -7.2900e-02, -1.9641e-02],\n",
       "          [-1.1812e+00, -8.5770e-01, -8.0817e-01,  ...,  2.9672e-01,\n",
       "            5.1015e-01,  4.6549e-01],\n",
       "          ...,\n",
       "          [ 3.0608e-01, -2.6736e-01, -6.0042e-02,  ...,  1.7309e-01,\n",
       "            3.8900e-02,  5.8613e-02],\n",
       "          [ 3.9269e-01, -4.4194e-01, -1.7120e-01,  ...,  4.8146e-03,\n",
       "            1.4139e-01,  7.6587e-02],\n",
       "          [ 5.7071e-01, -2.1592e-01, -2.1022e-01,  ..., -4.6224e-02,\n",
       "            1.4328e-02, -3.5934e-02]],\n",
       "\n",
       "         [[ 9.6720e-02, -1.4714e-02, -1.2146e-01,  ...,  2.6232e-01,\n",
       "           -8.4466e-02,  8.9256e-03],\n",
       "          [-3.1766e-01, -2.0167e-01, -2.1439e-02,  ..., -2.1835e-01,\n",
       "           -5.4020e-02, -3.3011e-02],\n",
       "          [-1.1993e+00, -8.2555e-01, -7.6527e-01,  ...,  2.8676e-01,\n",
       "            5.5264e-01,  4.3961e-01],\n",
       "          ...,\n",
       "          [ 2.8539e-01, -2.8951e-01, -6.0112e-02,  ...,  1.5975e-01,\n",
       "            4.3977e-02,  5.7532e-02],\n",
       "          [ 3.7329e-01, -4.6457e-01, -1.7547e-01,  ..., -1.4041e-02,\n",
       "            1.5025e-01,  7.7889e-02],\n",
       "          [ 5.5614e-01, -2.4247e-01, -2.1810e-01,  ..., -6.6110e-02,\n",
       "            2.3031e-02, -3.7823e-02]],\n",
       "\n",
       "         [[ 1.2059e-01,  2.3374e-03, -1.1293e-01,  ...,  1.9383e-01,\n",
       "           -2.6948e-02, -1.2234e-02],\n",
       "          [-3.2859e-01, -2.1746e-01, -2.0532e-03,  ..., -2.1200e-01,\n",
       "           -5.0534e-02, -1.1646e-02],\n",
       "          [-1.1866e+00, -8.6270e-01, -7.9769e-01,  ...,  2.8997e-01,\n",
       "            5.3063e-01,  4.7580e-01],\n",
       "          ...,\n",
       "          [ 3.0879e-01, -2.6988e-01, -6.0807e-02,  ...,  1.7082e-01,\n",
       "            5.3740e-02,  5.8492e-02],\n",
       "          [ 3.9557e-01, -4.4354e-01, -1.7107e-01,  ...,  2.0288e-03,\n",
       "            1.5500e-01,  7.5627e-02],\n",
       "          [ 5.7323e-01, -2.1890e-01, -2.1058e-01,  ..., -4.8806e-02,\n",
       "            2.8401e-02, -3.6836e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.6480e-02, -2.5101e-01, -1.8969e-01,  ...,  2.9901e-01,\n",
       "           -2.9133e-01, -9.9685e-02],\n",
       "          [ 4.3939e-01,  8.8307e-01, -9.5785e-01,  ...,  1.2707e+00,\n",
       "           -3.9019e-01, -1.8794e+00],\n",
       "          [-3.5249e-01,  2.4349e-01,  6.4738e-02,  ..., -3.7734e-01,\n",
       "            1.4168e-01, -1.2469e+00],\n",
       "          ...,\n",
       "          [ 5.6392e-01, -5.7138e-01,  4.5479e-01,  ...,  7.5100e-02,\n",
       "            5.9110e-02,  1.6421e-02],\n",
       "          [ 7.0388e-01, -8.1373e-01,  2.7466e-01,  ..., -1.7948e-01,\n",
       "            2.2169e-01,  3.9706e-02],\n",
       "          [ 9.4408e-01, -5.4592e-01,  3.0791e-01,  ..., -2.1959e-01,\n",
       "            1.7789e-02, -1.6949e-01]],\n",
       "\n",
       "         [[-6.0689e-03, -3.8039e-01, -1.1503e-01,  ...,  3.3840e-01,\n",
       "           -4.1020e-01, -5.9365e-02],\n",
       "          [ 2.2843e-01, -2.5268e-01,  3.1500e-02,  ...,  7.0458e-01,\n",
       "            4.8554e-01,  4.8111e-01],\n",
       "          [-4.7324e-01, -4.4736e-01, -1.7430e-01,  ..., -6.4425e-03,\n",
       "            1.2823e+00, -6.1655e-01],\n",
       "          ...,\n",
       "          [ 6.4627e-01, -7.2601e-01,  5.7432e-01,  ...,  3.9650e-02,\n",
       "            1.8615e-02,  5.7583e-02],\n",
       "          [ 7.9885e-01, -9.7585e-01,  4.0761e-01,  ..., -1.9245e-01,\n",
       "            1.8700e-01,  8.7148e-02],\n",
       "          [ 1.0709e+00, -7.3417e-01,  4.0854e-01,  ..., -2.2098e-01,\n",
       "            1.4742e-03, -9.5844e-02]],\n",
       "\n",
       "         [[ 1.5518e-02, -3.1625e-01, -1.8245e-01,  ...,  3.3911e-01,\n",
       "           -3.5587e-01, -6.8606e-02],\n",
       "          [-2.5444e-01, -2.5518e-01,  1.8229e-01,  ...,  1.4794e-01,\n",
       "           -2.7217e-01, -2.3596e-01],\n",
       "          [-1.0094e+00, -8.9171e-01,  3.3008e-02,  ...,  6.3668e-01,\n",
       "            3.4995e-01,  1.7385e-01],\n",
       "          ...,\n",
       "          [ 6.7054e-01, -6.8834e-01,  4.8288e-01,  ...,  9.9750e-02,\n",
       "            4.5469e-02,  5.5774e-02],\n",
       "          [ 8.2420e-01, -9.3717e-01,  2.9941e-01,  ..., -1.3105e-01,\n",
       "            2.1417e-01,  8.0657e-02],\n",
       "          [ 1.1072e+00, -6.6054e-01,  3.1587e-01,  ..., -1.6556e-01,\n",
       "            8.7317e-03, -1.3375e-01]],\n",
       "\n",
       "         [[ 4.1840e-02, -2.7073e-01, -2.2377e-01,  ...,  3.1853e-01,\n",
       "           -2.6694e-01, -6.8355e-02],\n",
       "          [-1.9836e-01, -3.0180e-01,  4.4050e-02,  ...,  8.9639e-02,\n",
       "           -1.6317e-01, -2.6727e-01],\n",
       "          [-9.7011e-01, -8.2551e-01,  1.3064e-02,  ...,  6.1201e-01,\n",
       "            4.6073e-01,  2.0160e-01],\n",
       "          ...,\n",
       "          [ 6.1511e-01, -6.5835e-01,  4.1865e-01,  ...,  4.8485e-02,\n",
       "            1.2442e-01,  8.5457e-02],\n",
       "          [ 7.5814e-01, -9.0138e-01,  2.4246e-01,  ..., -1.9580e-01,\n",
       "            2.9851e-01,  1.1033e-01],\n",
       "          [ 1.0381e+00, -6.2694e-01,  2.4137e-01,  ..., -2.3954e-01,\n",
       "            9.0838e-02, -1.0080e-01]],\n",
       "\n",
       "         [[ 3.2672e-02, -3.1316e-01, -1.6442e-01,  ...,  3.3074e-01,\n",
       "           -3.6878e-01, -7.0138e-02],\n",
       "          [-2.3983e-01, -2.2307e-01,  2.1291e-01,  ...,  1.6066e-01,\n",
       "           -2.1655e-01, -2.0333e-01],\n",
       "          [-1.0221e+00, -8.9898e-01,  1.2348e-02,  ...,  6.5357e-01,\n",
       "            4.0529e-01,  1.9881e-01],\n",
       "          ...,\n",
       "          [ 6.7260e-01, -6.9045e-01,  4.9515e-01,  ...,  1.0002e-01,\n",
       "            5.8368e-02,  6.3493e-02],\n",
       "          [ 8.2610e-01, -9.3675e-01,  3.1489e-01,  ..., -1.3247e-01,\n",
       "            2.2650e-01,  8.4876e-02],\n",
       "          [ 1.1097e+00, -6.6265e-01,  3.2949e-01,  ..., -1.6350e-01,\n",
       "            2.6421e-02, -1.2658e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-5.2829e-01, -4.7502e-01,  4.4312e-01,  ..., -1.4147e-01,\n",
       "            3.8482e-02, -2.9834e-01],\n",
       "          [ 6.1603e-02,  1.1080e+00,  5.2799e-01,  ...,  8.0744e-01,\n",
       "            1.4004e-01, -6.8327e-01],\n",
       "          [-6.0465e-01,  6.3061e-01,  7.8043e-01,  ...,  9.2129e-01,\n",
       "            5.6181e-01, -6.9192e-01],\n",
       "          ...,\n",
       "          [ 2.2574e-01, -5.2019e-01,  1.0663e+00,  ..., -8.1776e-01,\n",
       "           -1.0105e-01, -9.4593e-01],\n",
       "          [ 1.6233e-01, -5.9059e-01,  9.7349e-01,  ..., -8.0431e-01,\n",
       "           -4.9216e-02, -1.0208e+00],\n",
       "          [ 3.2065e-01, -3.6955e-01,  9.2955e-01,  ..., -7.2512e-01,\n",
       "           -2.0157e-01, -1.4447e+00]],\n",
       "\n",
       "         [[-5.7539e-01, -3.9950e-01,  2.4704e-01,  ..., -1.1602e-01,\n",
       "            9.8937e-02, -4.1108e-01],\n",
       "          [ 1.4331e-01,  4.1176e-01, -2.4353e-01,  ..., -5.1563e-01,\n",
       "            3.1187e-01,  8.8190e-03],\n",
       "          [ 1.3180e-01,  4.3138e-01,  1.3513e-01,  ..., -1.0377e+00,\n",
       "            4.3424e-01, -3.3305e-01],\n",
       "          ...,\n",
       "          [ 2.6393e-01, -4.7775e-01,  1.1039e+00,  ..., -8.9278e-01,\n",
       "           -2.0791e-01, -1.0175e+00],\n",
       "          [ 2.3510e-01, -5.8463e-01,  9.9358e-01,  ..., -8.7310e-01,\n",
       "           -1.4243e-01, -1.0705e+00],\n",
       "          [ 4.8160e-01, -3.5830e-01,  9.5695e-01,  ..., -7.7033e-01,\n",
       "           -2.9237e-01, -1.4348e+00]],\n",
       "\n",
       "         [[-5.2371e-01, -4.5999e-01,  2.2500e-01,  ...,  2.7237e-02,\n",
       "            2.6062e-01, -3.4376e-01],\n",
       "          [-5.5685e-02, -4.9518e-01,  8.6226e-01,  ..., -4.3630e-01,\n",
       "            7.7633e-01, -7.3250e-01],\n",
       "          [-1.5384e-01,  1.4220e-01,  6.6147e-01,  ..., -4.7531e-01,\n",
       "            7.3238e-01, -2.6567e-01],\n",
       "          ...,\n",
       "          [ 1.9071e-01, -6.0006e-01,  1.0906e+00,  ..., -8.3144e-01,\n",
       "           -1.0978e-01, -9.4274e-01],\n",
       "          [ 1.4595e-01, -7.0738e-01,  9.6367e-01,  ..., -8.0607e-01,\n",
       "           -5.8973e-02, -1.0076e+00],\n",
       "          [ 4.0118e-01, -4.8235e-01,  9.0967e-01,  ..., -7.1132e-01,\n",
       "           -2.2295e-01, -1.4189e+00]],\n",
       "\n",
       "         [[-5.0042e-01, -6.3709e-01,  1.8913e-01,  ...,  1.9882e-01,\n",
       "            2.8912e-01, -3.0104e-01],\n",
       "          [-3.2085e-01, -4.4695e-01,  3.3552e-01,  ..., -2.6370e-01,\n",
       "            8.0511e-01, -8.4352e-01],\n",
       "          [-3.2406e-01,  1.0299e-01,  2.9958e-01,  ..., -6.0411e-01,\n",
       "            9.5498e-01, -4.1566e-03],\n",
       "          ...,\n",
       "          [ 1.9423e-01, -6.6890e-01,  1.0703e+00,  ..., -8.4363e-01,\n",
       "           -7.9043e-02, -8.6132e-01],\n",
       "          [ 1.8907e-01, -8.0769e-01,  9.6274e-01,  ..., -7.9173e-01,\n",
       "           -3.4632e-02, -9.5420e-01],\n",
       "          [ 4.1395e-01, -6.0564e-01,  8.3318e-01,  ..., -6.9977e-01,\n",
       "           -2.1702e-01, -1.4411e+00]],\n",
       "\n",
       "         [[-5.1943e-01, -4.9120e-01,  2.1547e-01,  ...,  2.4564e-02,\n",
       "            2.7534e-01, -3.5904e-01],\n",
       "          [-1.1068e-01, -4.7370e-01,  6.6794e-01,  ..., -6.5904e-01,\n",
       "            7.8836e-01, -8.9247e-01],\n",
       "          [-2.4873e-01,  9.1014e-02,  6.1647e-01,  ..., -5.0330e-01,\n",
       "            6.1759e-01, -3.9327e-01],\n",
       "          ...,\n",
       "          [ 1.8345e-01, -5.9674e-01,  1.1022e+00,  ..., -8.0633e-01,\n",
       "           -9.4151e-02, -9.1675e-01],\n",
       "          [ 1.4192e-01, -7.0369e-01,  9.7836e-01,  ..., -7.7463e-01,\n",
       "           -4.2933e-02, -9.8229e-01],\n",
       "          [ 3.9203e-01, -4.8914e-01,  9.2337e-01,  ..., -6.8097e-01,\n",
       "           -1.9610e-01, -1.3918e+00]]],\n",
       "\n",
       "\n",
       "        [[[-2.3286e-01, -1.1855e-01,  4.9010e-01,  ..., -2.4907e-01,\n",
       "            2.7919e-01, -3.7599e-01],\n",
       "          [-5.9538e-02,  8.4500e-01,  4.1052e-01,  ...,  1.4461e-01,\n",
       "            1.5832e-01, -6.6367e-01],\n",
       "          [-3.8935e-01,  1.4720e-01,  7.6488e-01,  ...,  5.9659e-01,\n",
       "            6.4696e-01, -7.0449e-01],\n",
       "          ...,\n",
       "          [ 3.4960e-01, -4.8408e-01,  1.1400e+00,  ..., -9.4434e-01,\n",
       "            7.6465e-02, -1.1011e+00],\n",
       "          [ 2.7907e-01, -5.1215e-01,  1.0657e+00,  ..., -9.3298e-01,\n",
       "            1.0585e-01, -1.1607e+00],\n",
       "          [ 4.5622e-01, -3.1540e-01,  9.7253e-01,  ..., -8.2982e-01,\n",
       "           -1.9100e-02, -1.6030e+00]],\n",
       "\n",
       "         [[-3.1739e-01, -4.8620e-02,  2.3689e-01,  ..., -2.9853e-01,\n",
       "            3.4733e-01, -4.7055e-01],\n",
       "          [ 3.6541e-01,  7.2652e-01, -3.4211e-01,  ..., -5.7418e-01,\n",
       "            7.6577e-01, -5.0833e-02],\n",
       "          [ 1.7445e-01,  1.0404e+00,  6.6417e-02,  ..., -9.3202e-01,\n",
       "            1.0605e+00, -6.6941e-02],\n",
       "          ...,\n",
       "          [ 4.1778e-01, -4.4121e-01,  1.2320e+00,  ..., -9.9687e-01,\n",
       "           -1.1364e-01, -1.1596e+00],\n",
       "          [ 3.8351e-01, -5.0161e-01,  1.1471e+00,  ..., -9.7877e-01,\n",
       "           -6.4349e-02, -1.1993e+00],\n",
       "          [ 6.5542e-01, -2.9592e-01,  1.0539e+00,  ..., -8.6016e-01,\n",
       "           -1.6741e-01, -1.5863e+00]],\n",
       "\n",
       "         [[-2.9160e-01, -9.4235e-02,  1.6953e-01,  ..., -1.4299e-01,\n",
       "            3.9885e-01, -3.4227e-01],\n",
       "          [-4.5742e-03, -2.9071e-01,  6.4626e-01,  ..., -3.7944e-01,\n",
       "            1.0962e+00, -6.8822e-01],\n",
       "          [-2.6288e-01,  7.9346e-01,  5.6411e-01,  ..., -5.8419e-01,\n",
       "            1.2260e+00,  1.9765e-01],\n",
       "          ...,\n",
       "          [ 3.3648e-01, -5.6411e-01,  1.1897e+00,  ..., -9.0002e-01,\n",
       "           -2.8344e-02, -1.1069e+00],\n",
       "          [ 2.7811e-01, -6.2866e-01,  1.0877e+00,  ..., -8.8236e-01,\n",
       "            6.9699e-03, -1.1596e+00],\n",
       "          [ 5.5831e-01, -4.1645e-01,  9.7949e-01,  ..., -7.6982e-01,\n",
       "           -1.0823e-01, -1.5898e+00]],\n",
       "\n",
       "         [[-2.8637e-01, -1.8023e-01,  4.5719e-02,  ..., -2.8373e-02,\n",
       "            3.5761e-01, -3.9302e-01],\n",
       "          [-9.6702e-02, -2.3416e-01, -2.6921e-01,  ..., -5.6385e-02,\n",
       "            1.0657e+00, -8.7811e-01],\n",
       "          [-2.6540e-01,  6.5254e-01,  4.5666e-02,  ..., -6.2798e-01,\n",
       "            1.1607e+00,  5.1637e-01],\n",
       "          ...,\n",
       "          [ 3.2938e-01, -5.7319e-01,  1.1745e+00,  ..., -9.1746e-01,\n",
       "            2.7747e-02, -1.0582e+00],\n",
       "          [ 3.0331e-01, -6.6528e-01,  1.0841e+00,  ..., -8.6926e-01,\n",
       "            5.1347e-02, -1.1385e+00],\n",
       "          [ 5.5106e-01, -4.6841e-01,  9.0903e-01,  ..., -7.6506e-01,\n",
       "           -7.4037e-02, -1.6346e+00]],\n",
       "\n",
       "         [[-3.3804e-01, -1.1319e-01,  1.4674e-01,  ..., -1.1317e-01,\n",
       "            4.3706e-01, -3.7588e-01],\n",
       "          [-7.1271e-02, -3.1115e-01,  3.5627e-01,  ..., -4.9607e-01,\n",
       "            1.1091e+00, -9.4398e-01],\n",
       "          [-4.4529e-01,  7.2085e-01,  4.4578e-01,  ..., -4.8847e-01,\n",
       "            1.0923e+00,  1.8924e-02],\n",
       "          ...,\n",
       "          [ 3.2429e-01, -5.7661e-01,  1.1937e+00,  ..., -8.7003e-01,\n",
       "           -1.8421e-02, -1.0801e+00],\n",
       "          [ 2.6831e-01, -6.4228e-01,  1.0934e+00,  ..., -8.4382e-01,\n",
       "            1.8579e-02, -1.1347e+00],\n",
       "          [ 5.4323e-01, -4.4081e-01,  9.8564e-01,  ..., -7.3428e-01,\n",
       "           -8.3842e-02, -1.5625e+00]]],\n",
       "\n",
       "\n",
       "        [[[-3.1380e-01,  2.4620e-01,  5.2846e-01,  ..., -2.6103e-01,\n",
       "            6.1474e-01, -5.0864e-01],\n",
       "          [ 1.6730e-02,  6.0886e-01,  1.8244e-02,  ...,  5.4304e-01,\n",
       "            6.6839e-01, -2.7589e-01],\n",
       "          [-2.1769e-01,  7.1509e-02,  8.9586e-01,  ...,  4.5966e-01,\n",
       "            1.2163e+00, -7.6951e-01],\n",
       "          ...,\n",
       "          [ 3.8876e-01, -3.3209e-01,  8.5745e-01,  ..., -7.5385e-01,\n",
       "           -4.4500e-02, -1.1235e+00],\n",
       "          [ 3.5605e-01, -3.6972e-01,  8.4037e-01,  ..., -7.7065e-01,\n",
       "           -4.2921e-02, -1.2014e+00],\n",
       "          [ 3.8454e-01, -3.0764e-01,  7.6826e-01,  ..., -6.8776e-01,\n",
       "           -8.2879e-02, -1.4351e+00]],\n",
       "\n",
       "         [[-5.4459e-01,  3.9570e-01,  4.4291e-01,  ..., -4.4564e-01,\n",
       "            5.7237e-01, -4.6021e-01],\n",
       "          [ 2.5856e-02,  5.0680e-01, -4.4709e-01,  ..., -3.1435e-02,\n",
       "            8.6462e-01,  1.3566e-01],\n",
       "          [ 1.6977e-01,  7.3030e-01, -1.1911e-01,  ..., -3.9449e-01,\n",
       "            9.4245e-01, -2.7938e-02],\n",
       "          ...,\n",
       "          [ 4.2708e-01, -2.4524e-01,  9.0513e-01,  ..., -7.6762e-01,\n",
       "           -6.2153e-02, -1.1299e+00],\n",
       "          [ 4.1298e-01, -2.9789e-01,  8.9089e-01,  ..., -7.8930e-01,\n",
       "           -4.4178e-02, -1.1998e+00],\n",
       "          [ 4.9556e-01, -2.1749e-01,  8.2296e-01,  ..., -7.0314e-01,\n",
       "           -8.4547e-02, -1.4285e+00]],\n",
       "\n",
       "         [[-6.0900e-01,  2.7827e-01,  3.2327e-01,  ..., -2.3054e-01,\n",
       "            7.6746e-01, -3.9005e-01],\n",
       "          [-2.3732e-01,  3.8009e-02,  3.1817e-01,  ..., -2.8796e-01,\n",
       "            1.1886e+00, -4.0502e-01],\n",
       "          [-2.7338e-01,  6.6019e-01,  3.2476e-01,  ..., -2.9976e-01,\n",
       "            7.5747e-01,  2.7462e-01],\n",
       "          ...,\n",
       "          [ 3.6959e-01, -2.9360e-01,  9.0572e-01,  ..., -7.2184e-01,\n",
       "           -2.9296e-02, -1.1011e+00],\n",
       "          [ 3.4303e-01, -3.5037e-01,  8.8522e-01,  ..., -7.4311e-01,\n",
       "           -1.9995e-02, -1.1733e+00],\n",
       "          [ 4.3082e-01, -2.7441e-01,  8.1228e-01,  ..., -6.6529e-01,\n",
       "           -6.2237e-02, -1.4335e+00]],\n",
       "\n",
       "         [[-6.4905e-01,  1.7676e-01,  1.5013e-01,  ..., -8.3356e-02,\n",
       "            8.1512e-01, -4.7562e-01],\n",
       "          [-5.2822e-01, -6.7259e-02, -5.2577e-01,  ...,  1.4961e-01,\n",
       "            1.2565e+00, -7.1437e-01],\n",
       "          [-2.3441e-01,  3.9487e-01, -1.6399e-01,  ..., -3.8212e-01,\n",
       "            6.5938e-01,  4.1206e-01],\n",
       "          ...,\n",
       "          [ 3.7194e-01, -3.1135e-01,  9.2320e-01,  ..., -7.5493e-01,\n",
       "           -5.3377e-02, -1.1242e+00],\n",
       "          [ 3.5806e-01, -3.7513e-01,  9.0702e-01,  ..., -7.6032e-01,\n",
       "           -5.2176e-02, -1.2034e+00],\n",
       "          [ 4.3076e-01, -3.1792e-01,  8.0644e-01,  ..., -6.8431e-01,\n",
       "           -8.6933e-02, -1.5022e+00]],\n",
       "\n",
       "         [[-6.6526e-01,  2.5823e-01,  3.2875e-01,  ..., -2.1449e-01,\n",
       "            7.7528e-01, -4.0710e-01],\n",
       "          [-2.9672e-01, -6.4161e-03,  5.7896e-02,  ..., -2.4000e-01,\n",
       "            1.1697e+00, -4.8048e-01],\n",
       "          [-4.0146e-01,  5.4376e-01,  1.9516e-01,  ..., -2.0822e-01,\n",
       "            7.2337e-01,  1.3537e-01],\n",
       "          ...,\n",
       "          [ 3.5248e-01, -2.9535e-01,  9.0342e-01,  ..., -6.8868e-01,\n",
       "           -1.6257e-02, -1.0784e+00],\n",
       "          [ 3.2553e-01, -3.5238e-01,  8.8371e-01,  ..., -7.0635e-01,\n",
       "           -6.1814e-03, -1.1512e+00],\n",
       "          [ 4.1446e-01, -2.8223e-01,  8.1306e-01,  ..., -6.3287e-01,\n",
       "           -4.2845e-02, -1.4101e+00]]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_state, dim=0)\n",
    "token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 5, 48, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap dimensions: [sentence, tokens, hidden layers, features]\n",
    "token_embeddings = token_embeddings.permute(1, 2, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 48, 13, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 48, 4, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_embeddings = token_embeddings[:, :, 9:, :]\n",
    "processed_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 48, 3072)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = torch.reshape(processed_embeddings, (5, 48, -1))\n",
    "embeddings = embeddings.detach().numpy()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14914590120315552"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(embeddings[2][3], embeddings[3][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01848292350769043"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(embeddings[2][3], embeddings[4][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3836, -0.2600,  0.4955,  ..., -0.2610,  0.6147, -0.5086],\n",
       "         [ 0.0668,  1.4839,  0.2340,  ...,  0.5430,  0.6684, -0.2759],\n",
       "         [-0.0511,  0.4364,  0.2815,  ...,  0.4597,  1.2163, -0.7695],\n",
       "         ...,\n",
       "         [ 0.2397, -0.5940,  1.0754,  ..., -0.7538, -0.0445, -1.1235],\n",
       "         [ 0.2003, -0.6420,  0.9748,  ..., -0.7706, -0.0429, -1.2014],\n",
       "         [ 0.3538, -0.4248,  0.9519,  ..., -0.6878, -0.0829, -1.4351]],\n",
       "\n",
       "        [[-0.3597, -0.3150,  0.3647,  ..., -0.4456,  0.5724, -0.4602],\n",
       "         [ 0.1983,  0.5558, -0.3408,  ..., -0.0314,  0.8646,  0.1357],\n",
       "         [ 0.3919,  0.1527, -0.0829,  ..., -0.3945,  0.9425, -0.0279],\n",
       "         ...,\n",
       "         [ 0.3015, -0.5256,  1.0983,  ..., -0.7676, -0.0622, -1.1299],\n",
       "         [ 0.2945, -0.6128,  0.9852,  ..., -0.7893, -0.0442, -1.1998],\n",
       "         [ 0.5366, -0.3880,  0.9748,  ..., -0.7031, -0.0845, -1.4285]],\n",
       "\n",
       "        [[-0.3195, -0.3453,  0.3377,  ..., -0.2305,  0.7675, -0.3901],\n",
       "         [-0.0812, -0.1572,  0.5675,  ..., -0.2880,  1.1886, -0.4050],\n",
       "         [-0.2663, -0.0352,  0.2904,  ..., -0.2998,  0.7575,  0.2746],\n",
       "         ...,\n",
       "         [ 0.2720, -0.6347,  1.0520,  ..., -0.7218, -0.0293, -1.1011],\n",
       "         [ 0.2472, -0.7210,  0.9152,  ..., -0.7431, -0.0200, -1.1733],\n",
       "         [ 0.4925, -0.4975,  0.8841,  ..., -0.6653, -0.0622, -1.4335]],\n",
       "\n",
       "        [[-0.2683, -0.4949,  0.3255,  ..., -0.0834,  0.8151, -0.4756],\n",
       "         [-0.1043, -0.2405,  0.3118,  ...,  0.1496,  1.2565, -0.7144],\n",
       "         [-0.2393, -0.1297,  0.0261,  ..., -0.3821,  0.6594,  0.4121],\n",
       "         ...,\n",
       "         [ 0.2417, -0.7332,  1.0467,  ..., -0.7549, -0.0534, -1.1242],\n",
       "         [ 0.2488, -0.8511,  0.9139,  ..., -0.7603, -0.0522, -1.2034],\n",
       "         [ 0.4709, -0.6308,  0.7969,  ..., -0.6843, -0.0869, -1.5022]],\n",
       "\n",
       "        [[-0.3132, -0.3844,  0.3173,  ..., -0.2145,  0.7753, -0.4071],\n",
       "         [-0.0950, -0.1379,  0.4879,  ..., -0.2400,  1.1697, -0.4805],\n",
       "         [-0.2914, -0.0802,  0.1784,  ..., -0.2082,  0.7234,  0.1354],\n",
       "         ...,\n",
       "         [ 0.2648, -0.6465,  1.0602,  ..., -0.6887, -0.0163, -1.0784],\n",
       "         [ 0.2432, -0.7313,  0.9263,  ..., -0.7063, -0.0062, -1.1512],\n",
       "         [ 0.4852, -0.5150,  0.8933,  ..., -0.6329, -0.0428, -1.4101]]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
