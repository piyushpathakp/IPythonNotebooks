{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'What the heck? Anyway, I do not care!', \n",
    "    'I am a British citizen.',\n",
    "    'He is the king of England.', \n",
    "    'He is the king of Python, a good machine learning engineer.',\n",
    "    'He is the king of Spain.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'the', 'heck', '?', 'anyway', ',', 'i', 'do', 'not', 'care', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0820 18:17:35.605566 46912496406208 tokenization_utils_base.py:1447] Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "W0820 18:17:35.607071 46912496406208 tokenization_utils.py:275] Keyword arguments {'trunction': True} not recognized.\n",
      "W0820 18:17:35.610715 46912496406208 tokenization_utils_base.py:1447] Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "W0820 18:17:35.612000 46912496406208 tokenization_utils.py:275] Keyword arguments {'trunction': True} not recognized.\n",
      "W0820 18:17:35.614071 46912496406208 tokenization_utils_base.py:1447] Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "W0820 18:17:35.615330 46912496406208 tokenization_utils.py:275] Keyword arguments {'trunction': True} not recognized.\n",
      "W0820 18:17:35.617269 46912496406208 tokenization_utils_base.py:1447] Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "W0820 18:17:35.618389 46912496406208 tokenization_utils.py:275] Keyword arguments {'trunction': True} not recognized.\n",
      "W0820 18:17:35.620712 46912496406208 tokenization_utils_base.py:1447] Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "W0820 18:17:35.621855 46912496406208 tokenization_utils.py:275] Keyword arguments {'trunction': True} not recognized.\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "tokenized_texts = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    marked_text = '[CLS]' + sentence + '[SEP]'\n",
    "    \n",
    "    encoded_dict = \\\n",
    "        tokenizer.encode_plus(\n",
    "                         sentence,\n",
    "                         add_special_tokens=True,\n",
    "                         trunction=True,\n",
    "                         max_length=48,\n",
    "                         pad_to_max_length=True,\n",
    "                         return_tensors='pt')\n",
    "    \n",
    "    \n",
    "    tokenized_texts.append(tokenizer.tokenize(marked_text))\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2002, 2003, 1996, 2332, 1997, 3577, 1012,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2054,  1996, 17752,  1029,  4312,  1010,  1045,  2079,  2025,\n",
       "          2729,   999,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1045,  2572,  1037,  2329,  6926,  1012,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2002,  2003,  1996,  2332,  1997,  2563,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2002,  2003,  1996,  2332,  1997, 18750,  1010,  1037,  2204,\n",
       "          3698,  4083,  3992,  1012,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2002,  2003,  1996,  2332,  1997,  3577,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_id = torch.LongTensor(np.array(input_ids>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    vec1, vec2, hidden_state = model(input_ids, segments_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 48, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n",
      "torch.Size([5, 48, 768])\n"
     ]
    }
   ],
   "source": [
    "for vec in hidden_state:\n",
    "    print(vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2708,  0.3256,  0.0573,  ..., -0.0324,  0.3578,  0.5502],\n",
       "         [ 0.3386,  0.4716, -0.1418,  ...,  0.4641,  0.7584, -0.0971],\n",
       "         [-0.0324,  0.2588,  0.3092,  ...,  0.2473,  1.4089, -0.2652],\n",
       "         ...,\n",
       "         [ 0.6796,  0.3689,  0.7275,  ...,  0.4562,  0.0854,  0.3063],\n",
       "         [ 0.1484,  0.0723,  0.4016,  ...,  0.5883,  0.1694,  0.1883],\n",
       "         [ 0.2493,  0.2640,  0.4613,  ...,  0.2719,  0.2291,  0.3422]],\n",
       "\n",
       "        [[ 0.1190,  0.3330, -0.2150,  ..., -0.2455,  0.4145,  0.7172],\n",
       "         [ 0.5392,  0.2716, -0.4211,  ..., -0.2646,  0.8108,  0.7869],\n",
       "         [ 0.5022,  0.1801, -0.0575,  ..., -0.7293,  0.6794,  0.8216],\n",
       "         ...,\n",
       "         [ 0.5527,  0.0522,  0.5830,  ..., -0.0652, -0.1205,  0.2030],\n",
       "         [-0.1811, -0.3234, -0.0653,  ...,  0.2794,  0.5110, -0.0428],\n",
       "         [-0.0302, -0.0978, -0.1857,  ...,  0.2594,  0.4029,  0.0332]],\n",
       "\n",
       "        [[-0.4268,  0.2247, -0.2767,  ..., -0.3985,  0.4350,  0.6681],\n",
       "         [-0.3115, -0.0246,  0.0555,  ..., -0.6938,  0.9881, -0.2296],\n",
       "         [-0.3886,  0.1786, -0.0168,  ..., -0.5829,  0.4937,  0.7960],\n",
       "         ...,\n",
       "         [-0.3574, -0.2702,  0.4611,  ...,  0.0589,  0.5501, -0.1300],\n",
       "         [-0.3584, -0.2909,  0.4620,  ...,  0.0690,  0.4730, -0.1919],\n",
       "         [-0.3842, -0.4756,  0.1512,  ...,  0.1106,  0.7060, -0.0765]],\n",
       "\n",
       "        [[-1.0869,  0.0435, -0.4206,  ..., -0.0076,  0.7398,  0.5000],\n",
       "         [-0.6635, -0.2656, -0.4720,  ...,  0.2916,  1.4000, -0.1273],\n",
       "         [-1.0518, -0.0310, -0.3192,  ...,  0.0669,  0.8687,  0.4948],\n",
       "         ...,\n",
       "         [-0.1654,  0.0048,  0.2117,  ...,  0.6040,  0.5209, -0.0912],\n",
       "         [-0.1340,  0.0955,  0.2223,  ...,  0.5636,  0.3854, -0.1453],\n",
       "         [ 0.0859,  0.0199,  0.2879,  ...,  0.5336,  0.3669, -0.0775]],\n",
       "\n",
       "        [[-0.6439,  0.1068, -0.1712,  ..., -0.5638,  0.6495,  0.5863],\n",
       "         [-0.4788, -0.0471,  0.1318,  ..., -0.6130,  1.1369, -0.3901],\n",
       "         [-0.7149, -0.0714,  0.0501,  ..., -0.3899,  0.6300,  0.5388],\n",
       "         ...,\n",
       "         [-0.5203, -0.1281,  0.5480,  ..., -0.0580,  0.5179, -0.2975],\n",
       "         [-0.5648, -0.1406,  0.4430,  ..., -0.0819,  0.4856, -0.3424],\n",
       "         [-0.6468, -0.5249,  0.2202,  ...,  0.0402,  0.8063, -0.1718]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8521, -0.3779, -0.9208,  ..., -0.6868, -0.6339,  0.9125],\n",
       "        [-0.8736, -0.4717, -0.8633,  ..., -0.6980, -0.6654,  0.8896],\n",
       "        [-0.8704, -0.5004, -0.7735,  ..., -0.4925, -0.7196,  0.8515],\n",
       "        [-0.7944, -0.5811, -0.9006,  ..., -0.6408, -0.7001,  0.7812],\n",
       "        [-0.9025, -0.5265, -0.8410,  ..., -0.6424, -0.7370,  0.8596]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 9.8677e-01,  4.5401e-01, -1.0180e+00,  ...,  7.5422e-01,\n",
       "            2.9288e-01, -1.5443e+00],\n",
       "          [-7.7901e-01,  4.7813e-01,  8.5864e-02,  ..., -2.4891e-01,\n",
       "            5.0784e-01, -5.6890e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]],\n",
       "\n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [-3.4023e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
       "            8.9008e-01,  1.6575e-01],\n",
       "          [-6.3496e-01,  1.9748e-01,  2.5116e-01,  ..., -4.0819e-02,\n",
       "            1.3468e+00, -6.9357e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]],\n",
       "\n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 5.4919e-03,  2.1535e-01,  2.6523e-01,  ...,  3.8705e-02,\n",
       "           -5.9142e-02,  2.8200e-01],\n",
       "          [-6.2703e-01, -6.3313e-02, -3.1428e-01,  ...,  3.4265e-01,\n",
       "            4.6361e-01,  4.5937e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]],\n",
       "\n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 5.4919e-03,  2.1535e-01,  2.6523e-01,  ...,  3.8705e-02,\n",
       "           -5.9142e-02,  2.8200e-01],\n",
       "          [-6.2703e-01, -6.3313e-02, -3.1428e-01,  ...,  3.4265e-01,\n",
       "            4.6361e-01,  4.5937e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]],\n",
       "\n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 5.4919e-03,  2.1535e-01,  2.6523e-01,  ...,  3.8705e-02,\n",
       "           -5.9142e-02,  2.8200e-01],\n",
       "          [-6.2703e-01, -6.3313e-02, -3.1428e-01,  ...,  3.4265e-01,\n",
       "            4.6361e-01,  4.5937e-01],\n",
       "          ...,\n",
       "          [ 1.4135e-01, -3.9700e-01, -6.2236e-02,  ...,  8.2293e-02,\n",
       "           -2.5761e-01,  2.5720e-01],\n",
       "          [ 2.0530e-01, -6.2230e-01, -2.4686e-01,  ..., -1.2149e-01,\n",
       "           -1.6731e-01,  2.4943e-01],\n",
       "          [ 4.1845e-01, -4.7524e-01, -1.8688e-01,  ..., -1.8926e-01,\n",
       "           -2.6207e-01,  1.4601e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.4036e-02,  1.0826e-01, -2.3394e-01,  ...,  1.5429e-01,\n",
       "           -6.0428e-03, -8.8670e-03],\n",
       "          [ 1.1515e+00,  9.5088e-01, -1.6074e+00,  ...,  9.8005e-01,\n",
       "           -2.3173e-01, -2.0535e+00],\n",
       "          [-3.2650e-01,  3.9938e-01, -2.0817e-02,  ..., -6.2551e-01,\n",
       "            5.4966e-01, -1.2950e+00],\n",
       "          ...,\n",
       "          [-1.0091e-01, -2.3212e-01,  2.2591e-01,  ...,  3.2997e-01,\n",
       "           -1.5922e-01, -2.0460e-01],\n",
       "          [-3.0082e-02, -3.9453e-01,  1.1983e-01,  ...,  1.9711e-01,\n",
       "           -3.9605e-02, -1.8691e-01],\n",
       "          [ 1.0017e-01, -2.6449e-01,  1.0826e-01,  ...,  1.7707e-01,\n",
       "           -1.2491e-01, -2.4412e-01]],\n",
       "\n",
       "         [[ 6.5330e-02,  6.3531e-02, -2.0908e-01,  ...,  1.9410e-01,\n",
       "           -3.6801e-02, -4.8502e-02],\n",
       "          [ 6.7122e-01,  7.7072e-01, -5.8756e-01,  ...,  2.1926e-01,\n",
       "            7.6958e-01, -3.8200e-03],\n",
       "          [-1.9280e-01,  2.5497e-01,  4.8958e-02,  ..., -3.6478e-01,\n",
       "            1.4397e+00, -7.2622e-01],\n",
       "          ...,\n",
       "          [-1.7045e-02, -2.2801e-01,  1.7953e-01,  ...,  3.2907e-01,\n",
       "           -2.9324e-01, -1.3763e-01],\n",
       "          [ 3.2331e-02, -3.8976e-01,  5.9727e-02,  ...,  1.7234e-01,\n",
       "           -1.8277e-01, -1.1893e-01],\n",
       "          [ 1.7384e-01, -2.4321e-01,  1.2391e-02,  ...,  1.4399e-01,\n",
       "           -2.2531e-01, -1.7250e-01]],\n",
       "\n",
       "         [[ 7.0173e-02,  1.2900e-01, -2.2410e-01,  ...,  1.5286e-01,\n",
       "           -1.6134e-02,  9.8262e-03],\n",
       "          [-6.9159e-02,  3.3345e-01,  2.3394e-01,  ..., -3.4001e-01,\n",
       "            1.3684e-01,  9.0193e-03],\n",
       "          [-8.6703e-01, -2.2492e-01, -6.0861e-01,  ..., -4.8197e-02,\n",
       "            5.3625e-01,  2.6881e-01],\n",
       "          ...,\n",
       "          [-7.9178e-02, -3.8724e-01,  2.8720e-01,  ...,  4.2328e-01,\n",
       "           -1.0018e-01, -2.4286e-01],\n",
       "          [-1.1762e-02, -5.5701e-01,  1.5504e-01,  ...,  2.6710e-01,\n",
       "            3.8798e-04, -2.2944e-01],\n",
       "          [ 9.9040e-02, -4.4168e-01,  1.3043e-01,  ...,  2.6141e-01,\n",
       "           -5.6558e-02, -2.9409e-01]],\n",
       "\n",
       "         [[ 7.4187e-02,  6.0003e-02, -2.1116e-01,  ...,  2.1032e-01,\n",
       "           -6.4518e-02,  3.9180e-02],\n",
       "          [-4.0482e-02,  2.8785e-01, -3.6656e-03,  ..., -3.0607e-01,\n",
       "            1.9903e-01,  6.4708e-02],\n",
       "          [-1.0370e+00, -4.1602e-01, -5.6713e-01,  ...,  4.6540e-02,\n",
       "            8.0142e-01,  4.3849e-01],\n",
       "          ...,\n",
       "          [-9.6425e-02, -3.9122e-01,  2.1537e-01,  ...,  1.6451e-01,\n",
       "           -1.0240e-01, -4.1412e-02],\n",
       "          [-2.5494e-02, -5.3734e-01,  1.0576e-01,  ...,  1.8410e-02,\n",
       "            4.8447e-03, -4.2879e-02],\n",
       "          [ 8.6432e-02, -4.3385e-01,  7.3271e-02,  ...,  1.2080e-02,\n",
       "           -6.2173e-02, -9.7701e-02]],\n",
       "\n",
       "         [[ 9.2208e-02,  1.0519e-01, -2.0353e-01,  ...,  1.3883e-01,\n",
       "           -1.2437e-02, -3.8454e-03],\n",
       "          [-6.8756e-02,  3.3473e-01,  2.1750e-01,  ..., -3.5709e-01,\n",
       "            2.6226e-01,  8.8323e-02],\n",
       "          [-8.9436e-01, -3.2660e-01, -6.0285e-01,  ..., -1.2989e-01,\n",
       "            6.4928e-01,  3.5870e-01],\n",
       "          ...,\n",
       "          [-3.7313e-02, -4.0374e-01,  1.6915e-01,  ...,  3.8148e-01,\n",
       "            1.4873e-01, -1.9064e-01],\n",
       "          [ 3.1732e-02, -5.6337e-01,  6.8889e-02,  ...,  2.3509e-01,\n",
       "            2.2008e-01, -1.7949e-01],\n",
       "          [ 1.3031e-01, -4.4080e-01,  3.9014e-02,  ...,  2.3994e-01,\n",
       "            1.5333e-01, -2.4654e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.1292e-01, -1.7478e-01, -4.7134e-01,  ...,  3.4949e-01,\n",
       "            5.9370e-02, -6.0856e-02],\n",
       "          [ 6.4688e-01,  1.2755e+00, -9.9654e-01,  ...,  1.5282e+00,\n",
       "           -3.2766e-01, -2.1222e+00],\n",
       "          [-2.3632e-01,  4.5475e-01,  2.0549e-01,  ..., -2.0736e-01,\n",
       "            3.6056e-01, -1.4125e+00],\n",
       "          ...,\n",
       "          [-2.5609e-01,  1.1150e-01,  2.0673e-01,  ...,  9.8135e-01,\n",
       "           -4.1397e-01, -2.5027e-01],\n",
       "          [-3.6153e-01, -5.9436e-02,  7.3761e-02,  ...,  8.7297e-01,\n",
       "           -2.7746e-01, -2.0827e-01],\n",
       "          [-2.8215e-01, -1.9672e-02, -1.6182e-01,  ...,  8.9415e-01,\n",
       "           -2.9899e-01, -2.9734e-01]],\n",
       "\n",
       "         [[-1.8638e-01, -3.3174e-01, -4.4719e-01,  ...,  4.1741e-01,\n",
       "            1.2777e-01,  4.4090e-02],\n",
       "          [ 5.2217e-01,  6.4540e-01,  5.9181e-02,  ...,  4.1066e-01,\n",
       "            6.4479e-01,  7.5253e-02],\n",
       "          [-3.5716e-02,  1.8106e-01,  4.7450e-01,  ...,  1.8526e-01,\n",
       "            1.0643e+00, -6.0658e-01],\n",
       "          ...,\n",
       "          [-2.1302e-01, -5.0858e-01,  1.8743e-01,  ...,  7.7118e-01,\n",
       "           -3.4043e-01, -2.2461e-01],\n",
       "          [-1.2285e-01, -4.6280e-01,  2.1267e-01,  ...,  8.4049e-01,\n",
       "           -2.5636e-01, -3.1379e-02],\n",
       "          [-6.4941e-02, -2.9293e-01, -2.0765e-02,  ...,  8.9811e-01,\n",
       "           -2.3678e-01, -2.9976e-02]],\n",
       "\n",
       "         [[-8.9696e-02, -2.8867e-01, -4.4497e-01,  ...,  3.7337e-01,\n",
       "            1.0049e-01,  3.1554e-02],\n",
       "          [-6.1139e-02,  1.6658e-01,  2.4817e-01,  ..., -2.0162e-01,\n",
       "            4.1909e-02, -3.4133e-01],\n",
       "          [-7.3157e-01, -4.6758e-01,  4.7186e-02,  ...,  1.8846e-01,\n",
       "            4.1643e-01, -1.7954e-01],\n",
       "          ...,\n",
       "          [-3.3862e-01, -6.1868e-01,  1.3343e-01,  ...,  8.8704e-01,\n",
       "           -3.5411e-01, -1.6269e-01],\n",
       "          [-2.0889e-01, -7.2732e-01,  8.7154e-02,  ...,  7.8734e-01,\n",
       "           -2.9084e-01, -1.3706e-01],\n",
       "          [ 9.3255e-02, -6.7649e-01,  3.6388e-03,  ...,  8.3158e-01,\n",
       "           -2.7215e-01, -2.8043e-01]],\n",
       "\n",
       "         [[-1.7365e-02, -2.3594e-01, -4.8522e-01,  ...,  3.6196e-01,\n",
       "            7.6522e-02,  4.2290e-02],\n",
       "          [-1.8336e-02,  1.1323e-01, -1.8448e-01,  ..., -1.6199e-01,\n",
       "            2.0263e-01, -2.3756e-01],\n",
       "          [-7.9648e-01, -5.2542e-01, -1.6395e-02,  ...,  3.8330e-01,\n",
       "            5.8037e-01,  1.8839e-01],\n",
       "          ...,\n",
       "          [-9.0938e-02, -4.2061e-01,  2.1471e-01,  ...,  6.2738e-01,\n",
       "           -2.8907e-01,  1.2235e-02],\n",
       "          [ 4.6143e-02, -4.9826e-01,  1.1083e-01,  ...,  4.4399e-01,\n",
       "           -2.0626e-01,  1.9802e-02],\n",
       "          [ 3.5381e-01, -4.6607e-01,  1.8395e-03,  ...,  4.3929e-01,\n",
       "           -2.6353e-01, -1.4208e-01]],\n",
       "\n",
       "         [[-5.7474e-02, -2.8100e-01, -4.0817e-01,  ...,  3.6524e-01,\n",
       "            7.3534e-02,  3.4866e-02],\n",
       "          [-2.8851e-02,  2.7310e-01,  3.0054e-01,  ..., -1.9844e-01,\n",
       "            2.0202e-01, -1.8756e-01],\n",
       "          [-7.7001e-01, -4.1445e-01,  6.7383e-02,  ...,  1.4514e-01,\n",
       "            5.7305e-01, -5.2261e-02],\n",
       "          ...,\n",
       "          [-3.2719e-01, -4.7230e-01,  5.3955e-02,  ...,  8.8535e-01,\n",
       "           -8.8889e-02, -9.2598e-02],\n",
       "          [-2.3446e-01, -5.4032e-01, -5.7948e-03,  ...,  7.7234e-01,\n",
       "           -4.8345e-02, -5.3048e-02],\n",
       "          [ 1.0962e-01, -5.2611e-01, -6.6028e-02,  ...,  8.5313e-01,\n",
       "           -3.7895e-02, -1.9845e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.0229e-01,  2.1358e-01, -2.7493e-01,  ..., -4.2985e-02,\n",
       "           -6.0812e-01,  3.6817e-01],\n",
       "          [ 4.6191e-01,  1.1780e+00,  3.3186e-01,  ...,  5.8342e-01,\n",
       "            4.0847e-01, -4.9838e-01],\n",
       "          [-3.9933e-01,  8.0121e-01,  7.9008e-01,  ...,  6.2077e-01,\n",
       "            5.4914e-01, -3.8199e-01],\n",
       "          ...,\n",
       "          [ 1.2464e+00,  1.4793e+00,  1.3690e+00,  ...,  5.7327e-01,\n",
       "           -3.1393e-01, -2.6407e-02],\n",
       "          [-5.5202e-01,  4.2506e-01, -1.8909e-01,  ...,  3.8185e-02,\n",
       "           -6.2807e-01,  4.1622e-01],\n",
       "          [-4.6861e-01,  6.3169e-01,  4.7184e-01,  ...,  1.1861e-01,\n",
       "           -3.8580e-01,  2.5510e-01]],\n",
       "\n",
       "         [[-6.0860e-02,  9.8662e-02, -7.6808e-01,  ..., -2.8169e-01,\n",
       "           -2.2611e-01,  6.5197e-01],\n",
       "          [ 6.6833e-01,  1.9920e-01, -3.9867e-01,  ..., -6.5988e-01,\n",
       "            1.8713e-01,  5.4049e-01],\n",
       "          [ 4.7802e-01,  5.7084e-03, -3.3064e-01,  ..., -1.0684e+00,\n",
       "            2.3407e-02,  2.9511e-01],\n",
       "          ...,\n",
       "          [ 6.9668e-01,  2.2520e-02,  8.3595e-01,  ...,  1.9945e-02,\n",
       "           -3.1626e-01, -5.4850e-01],\n",
       "          [-7.1510e-01, -4.3738e-01, -4.0738e-01,  ..., -4.9581e-01,\n",
       "            4.3709e-02, -2.7046e-01],\n",
       "          [-7.6482e-01, -2.4059e-01, -1.1046e+00,  ..., -4.3323e-01,\n",
       "           -3.7101e-01, -1.4972e-02]],\n",
       "\n",
       "         [[-5.1025e-01, -3.4677e-01, -4.5655e-01,  ..., -1.2580e-01,\n",
       "            3.1996e-01,  8.0697e-01],\n",
       "          [-3.6136e-01, -9.8148e-01,  7.0015e-01,  ..., -5.7642e-01,\n",
       "            3.2450e-01, -5.9199e-01],\n",
       "          [-3.3923e-01, -5.0299e-01,  3.3284e-01,  ..., -3.7430e-01,\n",
       "            4.3833e-01,  1.9596e-02],\n",
       "          ...,\n",
       "          [-7.3478e-01, -7.6084e-01,  6.2581e-01,  ..., -2.0459e-01,\n",
       "            4.6500e-01, -4.8078e-01],\n",
       "          [-6.6597e-01, -8.4281e-01,  6.5018e-01,  ..., -1.2355e-01,\n",
       "            3.9170e-01, -7.3716e-01],\n",
       "          [-9.7055e-01, -9.0899e-01,  2.3051e-02,  ..., -5.6758e-01,\n",
       "            4.0192e-01, -1.3820e-01]],\n",
       "\n",
       "         [[-1.2308e+00, -7.3807e-01, -5.5457e-01,  ...,  1.5704e-01,\n",
       "            6.3435e-01,  2.8946e-01],\n",
       "          [-1.1052e+00, -1.0506e+00, -4.8019e-02,  ...,  3.4778e-01,\n",
       "            9.7819e-01, -2.4684e-01],\n",
       "          [-1.6565e+00, -8.1997e-01, -9.8058e-04,  ...,  1.2672e-01,\n",
       "            9.2439e-01,  3.1837e-01],\n",
       "          ...,\n",
       "          [-4.7804e-01, -2.6939e-01,  5.0960e-01,  ...,  1.0846e+00,\n",
       "            5.9961e-01, -9.8758e-02],\n",
       "          [-2.2949e-01, -2.7192e-02,  7.3187e-01,  ...,  1.1939e+00,\n",
       "            5.5535e-01, -3.1507e-01],\n",
       "          [ 4.2716e-01,  1.2400e-02,  8.1465e-01,  ...,  9.6936e-01,\n",
       "            6.6294e-01, -3.1182e-01]],\n",
       "\n",
       "         [[-8.0794e-01, -5.9099e-01, -4.2595e-01,  ..., -4.7900e-02,\n",
       "            4.9134e-01,  6.3801e-01],\n",
       "          [-4.8566e-01, -7.4701e-01,  7.4797e-01,  ..., -5.6258e-01,\n",
       "            7.1204e-01, -7.4369e-01],\n",
       "          [-6.7519e-01, -6.5485e-01,  3.5615e-01,  ..., -1.4264e-01,\n",
       "            5.0568e-01, -2.7320e-01],\n",
       "          ...,\n",
       "          [-8.0156e-01, -5.8903e-01,  7.6626e-01,  ..., -1.4998e-01,\n",
       "            8.3222e-01, -7.9657e-01],\n",
       "          [-9.5516e-01, -7.1466e-01,  6.9012e-01,  ..., -1.3836e-01,\n",
       "            7.5476e-01, -1.0252e+00],\n",
       "          [-1.1780e+00, -9.8253e-01,  1.0667e-01,  ..., -4.9750e-01,\n",
       "            7.5101e-01, -4.1505e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3841e-01,  2.0212e-01,  1.4966e-01,  ..., -1.3859e-01,\n",
       "            2.3884e-01,  2.6884e-01],\n",
       "          [ 4.5752e-01,  8.2246e-01,  1.1876e-02,  ..., -7.1301e-02,\n",
       "            5.8567e-01, -3.8834e-01],\n",
       "          [-1.8614e-01,  6.0992e-01,  6.7310e-01,  ...,  1.5480e-01,\n",
       "            8.3340e-01, -2.9174e-01],\n",
       "          ...,\n",
       "          [ 1.3339e+00,  1.3405e+00,  1.5397e+00,  ...,  6.2644e-01,\n",
       "           -1.8712e-01,  2.6983e-01],\n",
       "          [-3.2221e-01,  2.2108e-01,  2.9964e-01,  ...,  3.4531e-01,\n",
       "           -1.5622e-01,  2.8937e-01],\n",
       "          [ 2.5527e-02,  7.3273e-01,  5.8603e-01,  ...,  1.2266e-01,\n",
       "            1.1554e-01,  3.1385e-01]],\n",
       "\n",
       "         [[ 2.4497e-01,  1.4463e-01, -3.7201e-01,  ..., -4.2864e-01,\n",
       "            2.1983e-01,  6.6282e-01],\n",
       "          [ 7.6369e-01,  2.6195e-01, -1.9170e-01,  ..., -6.6209e-01,\n",
       "            6.3819e-01,  8.2285e-01],\n",
       "          [ 4.6994e-01,  2.8887e-01, -1.4351e-01,  ..., -1.0155e+00,\n",
       "            7.0686e-01,  9.4429e-01],\n",
       "          ...,\n",
       "          [ 1.1186e+00, -8.9389e-02,  1.0155e+00,  ..., -3.1197e-01,\n",
       "           -2.7968e-01,  2.8432e-01],\n",
       "          [-4.1141e-01, -3.7423e-01, -1.3912e-01,  ..., -1.6380e-01,\n",
       "            4.4942e-01, -1.1593e-01],\n",
       "          [-2.9902e-01, -1.8081e-01, -4.7463e-01,  ..., -2.1886e-01,\n",
       "            2.5088e-01,  1.8815e-01]],\n",
       "\n",
       "         [[-3.3240e-01, -2.7444e-02, -2.7747e-01,  ..., -3.1909e-01,\n",
       "            7.5637e-01,  7.8311e-01],\n",
       "          [-1.4708e-01, -5.1322e-01,  6.2454e-01,  ..., -6.6598e-01,\n",
       "            1.0566e+00, -1.7945e-01],\n",
       "          [-4.9584e-01,  9.1689e-02,  3.8570e-01,  ..., -5.3335e-01,\n",
       "            8.4170e-01,  7.9602e-01],\n",
       "          ...,\n",
       "          [-5.7222e-01, -4.6446e-01,  1.1173e+00,  ..., -3.2205e-02,\n",
       "            6.9334e-01, -2.8730e-01],\n",
       "          [-6.0917e-01, -5.2249e-01,  1.1814e+00,  ...,  5.1207e-02,\n",
       "            6.0945e-01, -4.3414e-01],\n",
       "          [-5.7965e-01, -6.6630e-01,  5.1158e-01,  ..., -2.5358e-01,\n",
       "            8.5487e-01, -1.2478e-01]],\n",
       "\n",
       "         [[-1.0974e+00, -2.6806e-01, -6.8642e-01,  ...,  2.3126e-02,\n",
       "            8.9345e-01,  4.8618e-01],\n",
       "          [-7.5123e-01, -5.0460e-01, -3.6934e-01,  ...,  1.5413e-01,\n",
       "            1.4402e+00, -2.3266e-01],\n",
       "          [-1.5936e+00,  6.6882e-02, -4.6487e-01,  ..., -5.0992e-02,\n",
       "            1.2932e+00,  9.1663e-01],\n",
       "          ...,\n",
       "          [-4.0545e-01,  6.8886e-02,  3.8313e-01,  ...,  1.0937e+00,\n",
       "            8.9511e-01, -1.4418e-01],\n",
       "          [-2.5140e-01,  3.1935e-01,  4.9437e-01,  ...,  1.1855e+00,\n",
       "            8.2201e-01, -3.2153e-01],\n",
       "          [ 2.0415e-01,  1.1705e-01,  4.8419e-01,  ...,  1.0367e+00,\n",
       "            6.6653e-01, -2.4186e-01]],\n",
       "\n",
       "         [[-7.3107e-01, -1.7719e-01, -3.1046e-01,  ..., -2.8154e-01,\n",
       "            7.8353e-01,  4.9845e-01],\n",
       "          [-5.2281e-01, -5.1500e-01,  5.0817e-01,  ..., -6.7674e-01,\n",
       "            1.2859e+00, -5.1359e-01],\n",
       "          [-9.5295e-01, -1.2501e-01,  1.4695e-01,  ..., -2.6769e-01,\n",
       "            9.4203e-01,  3.6882e-01],\n",
       "          ...,\n",
       "          [-9.9882e-01, -2.5217e-01,  1.1094e+00,  ..., -6.1217e-02,\n",
       "            7.6467e-01, -7.4008e-01],\n",
       "          [-1.1367e+00, -3.0451e-01,  9.8464e-01,  ..., -8.6537e-02,\n",
       "            7.1039e-01, -8.3923e-01],\n",
       "          [-1.0479e+00, -6.9305e-01,  4.7419e-01,  ..., -7.1711e-02,\n",
       "            9.8018e-01, -5.6640e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.7085e-01,  3.2557e-01,  5.7275e-02,  ..., -3.2379e-02,\n",
       "            3.5779e-01,  5.5017e-01],\n",
       "          [ 3.3863e-01,  4.7162e-01, -1.4183e-01,  ...,  4.6406e-01,\n",
       "            7.5837e-01, -9.7132e-02],\n",
       "          [-3.2376e-02,  2.5880e-01,  3.0921e-01,  ...,  2.4734e-01,\n",
       "            1.4089e+00, -2.6518e-01],\n",
       "          ...,\n",
       "          [ 6.7958e-01,  3.6887e-01,  7.2752e-01,  ...,  4.5625e-01,\n",
       "            8.5384e-02,  3.0630e-01],\n",
       "          [ 1.4838e-01,  7.2307e-02,  4.0163e-01,  ...,  5.8834e-01,\n",
       "            1.6945e-01,  1.8829e-01],\n",
       "          [ 2.4931e-01,  2.6399e-01,  4.6127e-01,  ...,  2.7194e-01,\n",
       "            2.2911e-01,  3.4220e-01]],\n",
       "\n",
       "         [[ 1.1902e-01,  3.3296e-01, -2.1505e-01,  ..., -2.4553e-01,\n",
       "            4.1453e-01,  7.1723e-01],\n",
       "          [ 5.3924e-01,  2.7160e-01, -4.2113e-01,  ..., -2.6458e-01,\n",
       "            8.1076e-01,  7.8689e-01],\n",
       "          [ 5.0219e-01,  1.8012e-01, -5.7535e-02,  ..., -7.2935e-01,\n",
       "            6.7936e-01,  8.2158e-01],\n",
       "          ...,\n",
       "          [ 5.5272e-01,  5.2202e-02,  5.8295e-01,  ..., -6.5164e-02,\n",
       "           -1.2053e-01,  2.0296e-01],\n",
       "          [-1.8108e-01, -3.2341e-01, -6.5268e-02,  ...,  2.7945e-01,\n",
       "            5.1099e-01, -4.2822e-02],\n",
       "          [-3.0209e-02, -9.7758e-02, -1.8568e-01,  ...,  2.5940e-01,\n",
       "            4.0295e-01,  3.3249e-02]],\n",
       "\n",
       "         [[-4.2680e-01,  2.2469e-01, -2.7669e-01,  ..., -3.9851e-01,\n",
       "            4.3497e-01,  6.6809e-01],\n",
       "          [-3.1152e-01, -2.4622e-02,  5.5512e-02,  ..., -6.9376e-01,\n",
       "            9.8809e-01, -2.2961e-01],\n",
       "          [-3.8858e-01,  1.7862e-01, -1.6826e-02,  ..., -5.8292e-01,\n",
       "            4.9369e-01,  7.9597e-01],\n",
       "          ...,\n",
       "          [-3.5741e-01, -2.7018e-01,  4.6113e-01,  ...,  5.8863e-02,\n",
       "            5.5015e-01, -1.3004e-01],\n",
       "          [-3.5838e-01, -2.9089e-01,  4.6204e-01,  ...,  6.8985e-02,\n",
       "            4.7296e-01, -1.9189e-01],\n",
       "          [-3.8417e-01, -4.7563e-01,  1.5122e-01,  ...,  1.1057e-01,\n",
       "            7.0599e-01, -7.6474e-02]],\n",
       "\n",
       "         [[-1.0869e+00,  4.3455e-02, -4.2057e-01,  ..., -7.5636e-03,\n",
       "            7.3976e-01,  5.0005e-01],\n",
       "          [-6.6354e-01, -2.6560e-01, -4.7199e-01,  ...,  2.9155e-01,\n",
       "            1.4000e+00, -1.2731e-01],\n",
       "          [-1.0518e+00, -3.1040e-02, -3.1923e-01,  ...,  6.6877e-02,\n",
       "            8.6872e-01,  4.9475e-01],\n",
       "          ...,\n",
       "          [-1.6540e-01,  4.7731e-03,  2.1174e-01,  ...,  6.0401e-01,\n",
       "            5.2089e-01, -9.1191e-02],\n",
       "          [-1.3398e-01,  9.5462e-02,  2.2234e-01,  ...,  5.6359e-01,\n",
       "            3.8541e-01, -1.4534e-01],\n",
       "          [ 8.5867e-02,  1.9894e-02,  2.8792e-01,  ...,  5.3362e-01,\n",
       "            3.6694e-01, -7.7533e-02]],\n",
       "\n",
       "         [[-6.4390e-01,  1.0678e-01, -1.7124e-01,  ..., -5.6381e-01,\n",
       "            6.4948e-01,  5.8630e-01],\n",
       "          [-4.7876e-01, -4.7126e-02,  1.3175e-01,  ..., -6.1304e-01,\n",
       "            1.1369e+00, -3.9009e-01],\n",
       "          [-7.1493e-01, -7.1401e-02,  5.0146e-02,  ..., -3.8986e-01,\n",
       "            6.2998e-01,  5.3877e-01],\n",
       "          ...,\n",
       "          [-5.2027e-01, -1.2807e-01,  5.4799e-01,  ..., -5.8039e-02,\n",
       "            5.1794e-01, -2.9748e-01],\n",
       "          [-5.6480e-01, -1.4064e-01,  4.4298e-01,  ..., -8.1883e-02,\n",
       "            4.8559e-01, -3.4236e-01],\n",
       "          [-6.4679e-01, -5.2494e-01,  2.2021e-01,  ...,  4.0245e-02,\n",
       "            8.0634e-01, -1.7183e-01]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_state, dim=0)\n",
    "token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 5, 48, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap dimensions: [sentence, tokens, hidden layers, features]\n",
    "token_embeddings = token_embeddings.permute(1, 2, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 48, 13, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 48, 4, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_embeddings = token_embeddings[:, :, 9:, :]\n",
    "processed_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 48, 3072)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = torch.reshape(processed_embeddings, (5, 48, -1))\n",
    "embeddings = embeddings.detach().numpy()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3443491458892822"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(embeddings[2][4], embeddings[3][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06491076946258545"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(embeddings[2][4], embeddings[4][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.24550708,  0.20207022, -0.615036  , ..., -0.0323792 ,\n",
       "          0.3577894 ,  0.550167  ],\n",
       "        [ 0.381902  ,  1.4579368 ,  0.01995093, ...,  0.46406403,\n",
       "          0.75837046, -0.09713171],\n",
       "        [-0.10853177,  0.5075319 ,  0.11464608, ...,  0.24733742,\n",
       "          1.4089295 , -0.2651754 ],\n",
       "        ...,\n",
       "        [ 1.0337685 ,  1.2701299 ,  1.4596736 , ...,  0.45624638,\n",
       "          0.08538438,  0.30630097],\n",
       "        [-0.625774  ,  0.62008536, -0.14527622, ...,  0.58833843,\n",
       "          0.1694477 ,  0.18828699],\n",
       "        [-0.41849947,  1.0807803 ,  0.67688525, ...,  0.2719449 ,\n",
       "          0.22910678,  0.3421992 ]],\n",
       "\n",
       "       [[ 0.03494433, -0.22927988, -1.027218  , ..., -0.24553123,\n",
       "          0.41452816,  0.7172312 ],\n",
       "        [ 0.7127029 ,  0.44174722, -0.62983584, ..., -0.2645788 ,\n",
       "          0.81075966,  0.7868859 ],\n",
       "        [ 0.7622329 ,  0.00343795, -0.3987933 , ..., -0.7293487 ,\n",
       "          0.67936385,  0.8215848 ],\n",
       "        ...,\n",
       "        [ 0.6663198 ,  0.15924904,  1.0996404 , ..., -0.06516441,\n",
       "         -0.12053021,  0.20295954],\n",
       "        [-0.43764874, -0.25104895, -0.46178678, ...,  0.27944598,\n",
       "          0.5109943 , -0.04282201],\n",
       "        [-0.53897417, -0.10966735, -1.2114623 , ...,  0.25940183,\n",
       "          0.4029494 ,  0.03324921]],\n",
       "\n",
       "       [[-0.49704263, -0.24412924, -0.77460915, ..., -0.3985072 ,\n",
       "          0.43497127,  0.668086  ],\n",
       "        [-0.3256378 , -0.25751597,  0.14123476, ..., -0.6937553 ,\n",
       "          0.9880878 , -0.22960748],\n",
       "        [-0.2669654 , -0.25877228, -0.15899242, ..., -0.5829235 ,\n",
       "          0.49368688,  0.79597485],\n",
       "        ...,\n",
       "        [-0.6230289 , -0.5766111 ,  0.45292848, ...,  0.05886343,\n",
       "          0.55014974, -0.13004412],\n",
       "        [-0.49986622, -0.7089433 ,  0.3601334 , ...,  0.06898512,\n",
       "          0.47296053, -0.1918895 ],\n",
       "        [-0.9755838 , -0.6269322 , -0.40748608, ...,  0.11057019,\n",
       "          0.7059904 , -0.07647378]],\n",
       "\n",
       "       [[-0.5606753 , -0.6692675 , -0.6198254 , ..., -0.00756362,\n",
       "          0.7397591 ,  0.5000499 ],\n",
       "        [-0.7053637 , -0.6830462 , -0.07042132, ...,  0.29155117,\n",
       "          1.4000187 , -0.12730864],\n",
       "        [-0.9850762 , -0.63732684, -0.17130847, ...,  0.0668771 ,\n",
       "          0.8687224 ,  0.4947549 ],\n",
       "        ...,\n",
       "        [-0.15730226, -0.0874157 ,  0.47364533, ...,  0.60401106,\n",
       "          0.52089167, -0.09119125],\n",
       "        [ 0.15797636,  0.03804386,  0.64449   , ...,  0.56358516,\n",
       "          0.38541242, -0.14533569],\n",
       "        [ 0.88804585, -0.09834158,  0.913196  , ...,  0.5336163 ,\n",
       "          0.36694014, -0.07753323]],\n",
       "\n",
       "       [[-0.6417776 , -0.44003063, -0.69285536, ..., -0.56381434,\n",
       "          0.6494797 ,  0.5863001 ],\n",
       "        [-0.41109976, -0.17946209,  0.16744775, ..., -0.6130443 ,\n",
       "          1.1368715 , -0.39009452],\n",
       "        [-0.480552  , -0.26226318, -0.15813465, ..., -0.38985804,\n",
       "          0.6299805 ,  0.53876656],\n",
       "        ...,\n",
       "        [-0.6086245 , -0.4796374 ,  0.39219657, ..., -0.05803862,\n",
       "          0.5179425 , -0.29748347],\n",
       "        [-0.66194373, -0.61344814,  0.20554084, ..., -0.08188296,\n",
       "          0.48558885, -0.34235898],\n",
       "        [-1.1007044 , -0.6795376 , -0.376665  , ...,  0.04024461,\n",
       "          0.8063395 , -0.17182684]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]',\n",
       "  'what',\n",
       "  'the',\n",
       "  'heck',\n",
       "  '?',\n",
       "  'anyway',\n",
       "  ',',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'care',\n",
       "  '!',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'i', 'am', 'a', 'british', 'citizen', '.', '[SEP]'],\n",
       " ['[CLS]', 'he', 'is', 'the', 'king', 'of', 'england', '.', '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'he',\n",
       "  'is',\n",
       "  'the',\n",
       "  'king',\n",
       "  'of',\n",
       "  'python',\n",
       "  ',',\n",
       "  'a',\n",
       "  'good',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'engineer',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['[CLS]', 'he', 'is', 'the', 'king', 'of', 'spain', '.', '[SEP]']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003948211669921875"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(vec2[0], vec2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
