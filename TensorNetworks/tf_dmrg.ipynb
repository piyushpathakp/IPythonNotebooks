{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensornetwork as tn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumDMRGLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, dimvec, pos_label, nblabels, bond_len, unihigh):\n",
    "        super(QuantumDMRGLayer, self).__init__()\n",
    "        self.dimvec = dimvec\n",
    "        self.pos_label = pos_label\n",
    "        self.nblabels = nblabels\n",
    "        self.m = bond_len\n",
    "        self.unihigh = unihigh\n",
    "\n",
    "        self.mps_tensors = [tf.Variable(tf.random.uniform(shape=self.mps_tensor_shape(i),\n",
    "                                                          minval=0,\n",
    "                                                          maxval=self.unihigh),\n",
    "                                        trainable=True,\n",
    "                                        name='mps_tensors_{}'.format(i))\n",
    "                            for i in range(self.dimvec)]\n",
    "\n",
    "    def mps_tensor_shape(self, idx):\n",
    "        if idx == 0 or idx == self.dimvec-1:\n",
    "            return (2, self.dimvec)\n",
    "        elif idx == self.pos_label:\n",
    "            return (2, self.dimvec, self.dimvec, self.nblabels)\n",
    "        else:\n",
    "            return (2, self.dimvec, self.dimvec)\n",
    "\n",
    "    def infer_single(self, input):\n",
    "        assert input.shape[0] == self.dimvec\n",
    "        assert input.shape[1] == 2\n",
    "        \n",
    "        nodes = [\n",
    "            tn.Node(self.mps_tensors[i], backend='tensorflow')\n",
    "            for i in range(self.dimvec)\n",
    "        ]\n",
    "        input_nodes = [\n",
    "            tn.Node(input[i, :], backend='tensorflow')\n",
    "            for i in range(self.dimvec)\n",
    "        ]\n",
    "\n",
    "        for i in range(self.dimvec):\n",
    "            nodes[i][0] ^ input_nodes[i][0]\n",
    "        nodes[0][1] ^ nodes[1][1]\n",
    "        for i in range(1, self.dimvec-1):\n",
    "            nodes[i][2] ^ nodes[i+1][1]\n",
    "\n",
    "        final_node = tn.contractors.auto(nodes + input_nodes,\n",
    "                                         output_edge_order=[nodes[self.pos_label][3]])\n",
    "        return final_node.tensor\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.vectorized_map(self.infer_single, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_dmrg_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(10, 2)),\n",
    "    QuantumDMRGLayer(dimvec=10, pos_label=5, nblabels=3, bond_len=5, unihigh=0.05),\n",
    "    # tf.keras.layers.Dense(3),\n",
    "    # tf.keras.layers.Softmax()\n",
    "])\n",
    "quantum_dmrg_model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7431630e-02, 3.07178330e-02, 2.24122293e-02],\n          [5.85508347e-03, 4.28246856e-02, 2.30904873e-02],\n          [2.34359987e-02, 4.45082858e-02, 1.40963318e-02],\n          [4.84372340e-02, 2.82031782e-02, 4.33179736e-02],\n          [4.18792330e-02, 3.07191610e-02, 2.37146802e-02],\n          [4.04254459e-02, 3.65561135e-02, 2.41609048e-02],\n          [3.21437381e-02, 1.56651735e-02, 2.29396168e-02],\n          [1.56141100e-02, 7.39735365e-03, 1.72497686e-02],\n          [1.58353690e-02, 2.00548172e-02, 4.94232178e-02],\n          [1.94491446e-02, 3.14465575e-02, 5.78522682e-04]],\n \n         [[2.43466794e-02, 4.52120081e-02, 1.16047328e-02],\n          [7.98987783e-03, 3.29398103e-02, 2.70730909e-02],\n          [4.86647002e-02, 3.62484753e-02, 2.79381704e-02],\n          [3.52992788e-02, 1.08714942e-02, 1.69741996e-02],\n          [2.96542943e-02, 1.13124195e-02, 1.75402761e-02],\n          [2.14590435e-03, 4.38815951e-02, 3.67909670e-02],\n          [1.00823641e-02, 4.04539099e-03, 3.37670441e-03],\n          [4.70617227e-02, 2.76168473e-02, 4.08376865e-02],\n          [3.78323309e-02, 1.72727706e-03, 1.73304267e-02],\n          [2.18710005e-02, 2.18388923e-02, 1.42366709e-02]],\n \n         [[1.43779814e-02, 1.52600883e-02, 4.70026135e-02],\n          [1.83059578e-03, 7.20078358e-03, 2.73319017e-02],\n          [2.84438971e-02, 1.62894782e-02, 1.60294529e-02],\n          [3.32656577e-02, 4.60272096e-02, 2.55389698e-02],\n          [9.46782250e-03, 2.32746787e-02, 3.30367088e-02],\n          [1.27825085e-02, 3.52122746e-02, 3.96918170e-02],\n          [4.31709401e-02, 1.97133012e-02, 4.93762493e-02],\n          [2.01958418e-02, 2.89683100e-02, 1.84861552e-02],\n          [3.80943678e-02, 3.49554420e-03, 4.13054936e-02],\n          [2.97465753e-02, 4.22477126e-02, 3.95487137e-02]],\n \n         [[1.13757430e-02, 4.07752767e-02, 1.88140702e-02],\n          [1.13234287e-02, 4.94338535e-02, 4.50093113e-02],\n          [2.01911032e-02, 4.51590233e-02, 2.19691582e-02],\n          [4.80226539e-02, 4.06002887e-02, 3.07275541e-02],\n          [4.08528149e-02, 3.02233938e-02, 3.83284353e-02],\n          [8.95609893e-03, 2.79442668e-02, 8.78597517e-03],\n          [1.03529394e-02, 2.69160513e-02, 2.25134497e-03],\n          [3.83141451e-02, 4.44414727e-02, 3.49411368e-03],\n          [3.34702320e-02, 1.17796538e-02, 3.60851064e-02],\n          [2.52955570e-03, 9.24082380e-03, 1.75622348e-02]],\n \n         [[7.20316172e-03, 2.65098456e-02, 3.24026309e-02],\n          [4.68512289e-02, 4.35030466e-04, 2.06951853e-02],\n          [4.24111858e-02, 3.41538973e-02, 2.18088813e-02],\n          [2.56084632e-02, 3.05761527e-02, 3.19189727e-02],\n          [1.49774076e-02, 4.07603383e-02, 4.09896970e-02],\n          [7.98952021e-03, 3.72762345e-02, 2.53922939e-02],\n          [1.90468375e-02, 4.88541238e-02, 4.22810018e-02],\n          [2.58354545e-02, 6.93894643e-03, 2.36086491e-02],\n          [1.53836487e-02, 2.35711392e-02, 2.15479149e-03],\n          [1.34699224e-02, 4.11297940e-02, 4.81054895e-02]],\n \n         [[1.67847108e-02, 1.09217111e-02, 3.74637241e-03],\n          [3.92206311e-02, 1.98733266e-02, 1.09978197e-02],\n          [2.12169718e-02, 2.41599865e-02, 1.04954187e-02],\n          [2.23765969e-02, 3.84634510e-02, 2.01400532e-03],\n          [4.79541384e-02, 4.23749052e-02, 9.45939403e-03],\n          [1.43216727e-02, 3.03988755e-02, 2.01026201e-02],\n          [9.09150857e-03, 4.33072411e-02, 3.86631861e-02],\n          [4.45415936e-02, 2.85788663e-02, 4.99474704e-02],\n          [4.83557582e-02, 1.14203813e-02, 1.22626899e-02],\n          [2.02802774e-02, 1.47138359e-02, 2.72587668e-02]],\n \n         [[3.40274647e-02, 1.60260201e-02, 4.95427870e-04],\n          [4.69751321e-02, 3.98554988e-02, 2.80859228e-02],\n          [4.07331660e-02, 2.79170107e-02, 1.98687203e-02],\n          [2.85212696e-02, 3.93785127e-02, 3.32401656e-02],\n          [2.24090461e-02, 1.26433074e-02, 1.06480662e-02],\n          [4.25109230e-02, 7.64551153e-03, 3.41316275e-02],\n          [3.69498506e-02, 8.70405417e-03, 1.17041711e-02],\n          [2.61650216e-02, 2.36375220e-02, 3.76216583e-02],\n          [4.66378890e-02, 1.12082241e-02, 4.14604321e-02],\n          [1.44731877e-02, 4.66274051e-03, 2.25274805e-02]],\n \n         [[3.19822319e-02, 7.88326841e-03, 2.63288803e-02],\n          [2.57033110e-03, 3.12424488e-02, 9.55911912e-03],\n          [1.36309089e-02, 3.43481191e-02, 1.79086514e-02],\n          [2.95374822e-02, 2.47344319e-02, 3.66613939e-02],\n          [2.67105531e-02, 2.29738187e-02, 1.81602072e-02],\n          [4.45270203e-02, 3.90745588e-02, 2.04972327e-02],\n          [4.65574861e-02, 3.79846208e-02, 5.37223229e-03],\n          [4.87216823e-02, 9.80744977e-03, 5.82789769e-03],\n          [1.03299199e-02, 4.70010601e-02, 4.93888278e-03],\n          [3.80938463e-02, 3.78880315e-02, 4.75246608e-02]]],\n \n \n        [[[4.92223492e-03, 4.46931496e-02, 1.67359714e-03],\n          [7.39119668e-03, 2.51863301e-02, 4.75923605e-02],\n          [1.78128667e-02, 4.74925339e-02, 1.11327115e-02],\n          [2.94398423e-02, 3.47110047e-03, 1.86710414e-02],\n          [1.08163003e-02, 4.30140272e-02, 4.48412485e-02],\n          [4.11100872e-02, 1.66579727e-02, 2.05689613e-02],\n          [4.35152166e-02, 6.34932541e-04, 2.28179451e-02],\n          [2.09539365e-02, 3.86976786e-02, 4.46288250e-02],\n          [1.56464037e-02, 9.08377208e-03, 2.67107077e-02],\n          [2.61923089e-03, 3.73633280e-02, 2.37128269e-02]],\n \n         [[4.03867988e-03, 1.70250367e-02, 3.34796309e-02],\n          [3.01530375e-03, 4.23736982e-02, 8.90256744e-03],\n          [1.61582064e-02, 3.26234512e-02, 4.38527428e-02],\n          [3.30174975e-02, 2.44803559e-02, 1.30511168e-02],\n          [1.73282567e-02, 1.54075865e-02, 1.38033330e-02],\n          [4.10328805e-02, 3.82479429e-02, 4.13728766e-02],\n          [1.20703578e-02, 3.26144807e-02, 9.26580466e-03],\n          [2.57812198e-02, 1.57485958e-02, 1.55721314e-03],\n          [4.06203344e-02, 1.43603152e-02, 1.08711962e-02],\n          [4.58230963e-03, 4.42185998e-03, 3.86648788e-03]],\n \n         [[2.15809289e-02, 2.93748509e-02, 1.41930347e-02],\n          [1.64983459e-02, 4.73719847e-04, 4.69561927e-02],\n          [3.03054210e-02, 4.77393381e-02, 2.31715795e-02],\n          [4.56202403e-02, 1.49460975e-02, 4.93291207e-02],\n          [2.98319757e-02, 3.79897356e-02, 1.77206527e-02],\n          [4.07483391e-02, 4.67404313e-02, 1.63169503e-02],\n          [1.32936006e-02, 1.62886027e-02, 3.67587223e-03],\n          [4.86525372e-02, 4.90662344e-02, 4.57306020e-02],\n          [3.45120439e-03, 2.94407015e-03, 1.14326002e-02],\n          [1.94546226e-02, 5.98654756e-03, 4.75465134e-02]],\n \n         [[8.98498285e-04, 1.76265892e-02, 1.54705588e-02],\n          [3.50679047e-02, 4.30027358e-02, 4.91962917e-02],\n          [4.55060303e-02, 4.31030355e-02, 3.89026999e-02],\n          [1.37015944e-02, 2.93105077e-02, 7.47444620e-03],\n          [4.97080646e-02, 1.38713839e-02, 1.64460782e-02],\n          [2.31740959e-02, 2.77666207e-02, 8.50632787e-03],\n          [6.27785316e-03, 2.88390759e-02, 4.63370495e-02],\n          [4.12354730e-02, 6.16055727e-03, 2.86108861e-03],\n          [1.79154275e-03, 1.24726659e-02, 3.14887166e-02],\n          [7.67238159e-03, 7.47966161e-03, 2.74228510e-02]],\n \n         [[4.17516194e-02, 4.12342660e-02, 4.89224568e-02],\n          [2.46274062e-02, 4.20315228e-02, 4.26615551e-02],\n          [1.76666919e-02, 4.97274883e-02, 4.94502205e-03],\n          [2.20196787e-02, 1.33932836e-03, 4.21742275e-02],\n          [3.99747863e-02, 2.49198321e-02, 2.80374587e-02],\n          [2.00220644e-02, 4.23738360e-03, 1.82047375e-02],\n          [4.99245599e-02, 2.64882459e-03, 2.48028990e-02],\n          [3.29982117e-02, 1.04664508e-02, 4.57795523e-02],\n          [4.02629785e-02, 3.40974517e-02, 2.09127311e-02],\n          [4.34503332e-02, 2.39722319e-02, 4.00350355e-02]],\n \n         [[2.63348110e-02, 3.10068671e-02, 3.90444808e-02],\n          [1.58096980e-02, 1.26661183e-02, 2.42618676e-02],\n          [4.15767096e-02, 6.89037470e-03, 2.64589917e-02],\n          [2.52980236e-02, 2.10157335e-02, 3.99111537e-03],\n          [4.75813225e-02, 3.98528278e-02, 1.90470945e-02],\n          [8.13186198e-05, 3.03242858e-02, 1.46470368e-02],\n          [1.78701226e-02, 1.40574872e-02, 3.68477218e-02],\n          [1.14198448e-02, 1.40498346e-02, 2.98874564e-02],\n          [1.78274810e-02, 1.27309738e-02, 5.13753900e-03],\n          [3.07934768e-02, 7.17244763e-03, 3.59046422e-02]],\n \n         [[6.06387854e-04, 3.83074544e-02, 2.66544949e-02],\n          [2.65756790e-02, 2.52298061e-02, 9.03584342e-03],\n          [2.63854694e-02, 3.06718107e-02, 4.24156450e-02],\n          [2.46882737e-02, 4.59465571e-02, 3.47506404e-02],\n          [1.23644536e-02, 3.27056652e-04, 2.08041854e-02],\n          [3.74380760e-02, 8.06949753e-03, 3.04971822e-02],\n          [4.77482043e-02, 4.82772551e-02, 4.99977246e-02],\n          [1.32912342e-02, 4.01922455e-03, 2.25624628e-02],\n          [2.69816406e-02, 1.88131090e-02, 2.62864530e-02],\n          [4.07662988e-02, 1.83098447e-02, 2.35081315e-02]],\n \n         [[2.41666026e-02, 3.41743305e-02, 4.35422687e-03],\n          [3.67892981e-02, 4.25938927e-02, 1.80858374e-03],\n          [9.02019721e-03, 4.34090495e-02, 1.69276837e-02],\n          [4.51226532e-02, 4.93898876e-02, 2.69973706e-02],\n          [2.46030036e-02, 8.26466072e-04, 3.94376628e-02],\n          [2.26878580e-02, 3.55625339e-02, 2.05942150e-02],\n          [2.93494458e-03, 3.00400201e-02, 2.21454035e-02],\n          [2.04178821e-02, 7.78616685e-03, 2.97110919e-02],\n          [2.65984125e-02, 1.67078264e-02, 9.84421372e-03],\n          [9.16109700e-03, 4.53684293e-02, 1.62059069e-02]],\n \n         [[3.06713171e-02, 1.32168056e-02, 4.30667959e-02],\n          [4.32578586e-02, 9.49226599e-03, 1.91901382e-02],\n          [3.40509973e-02, 5.21557918e-03, 1.73805244e-02],\n          [3.05260010e-02, 4.04816978e-02, 4.65733185e-02],\n          [1.01172925e-04, 8.46650638e-03, 2.71876510e-02],\n          [2.89516803e-02, 1.23707354e-02, 2.14898642e-02],\n          [1.97039135e-02, 3.43838744e-02, 1.08232675e-02],\n          [2.43608654e-02, 2.53990479e-02, 3.33238835e-03],\n          [2.47825379e-03, 2.49184556e-02, 1.13838911e-02],\n          [3.61814871e-02, 3.96817736e-02, 1.74874421e-02]],\n \n         [[3.94462608e-02, 3.91900651e-02, 4.04708795e-02],\n          [7.10933795e-03, 4.76499870e-02, 1.54161220e-02],\n          [1.27934096e-02, 3.88818997e-04, 4.45621042e-03],\n          [4.18853648e-02, 1.67850498e-02, 1.65889449e-02],\n          [2.14936566e-02, 1.26038613e-02, 3.11132129e-02],\n          [2.86474526e-02, 3.40574570e-02, 2.77331304e-02],\n          [2.83776708e-02, 2.27078032e-02, 7.11551914e-03],\n          [1.82435755e-02, 2.85034366e-02, 9.98436194e-03],\n          [3.66976149e-02, 2.37751010e-04, 1.02495132e-02],\n          [3.91626433e-02, 4.03157845e-02, 2.73990221e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'mps_tensors_6:0' shape=(2, 10, 10) dtype=float32, numpy=\n array([[[0.03172038, 0.03575121, 0.04740959, 0.03827432, 0.02611867,\n          0.00589619, 0.04190233, 0.01130461, 0.03993187, 0.02820602],\n         [0.01565458, 0.02350894, 0.04259473, 0.01830423, 0.03487859,\n          0.00269266, 0.0492875 , 0.04125307, 0.01000981, 0.0415119 ],\n         [0.04895467, 0.04729116, 0.04660426, 0.01301258, 0.02365521,\n          0.01966568, 0.01760076, 0.00684844, 0.04959855, 0.02605076],\n         [0.03293208, 0.00540351, 0.0204544 , 0.00205951, 0.01187112,\n          0.0010598 , 0.03634769, 0.0381785 , 0.03545438, 0.01704261],\n         [0.04051284, 0.03941779, 0.01758156, 0.02997256, 0.01017789,\n          0.02740043, 0.04700458, 0.0435993 , 0.04773933, 0.04010404],\n         [0.00186435, 0.03729495, 0.02304707, 0.04905995, 0.02895066,\n          0.00727134, 0.03040217, 0.02478204, 0.03223635, 0.01970873],\n         [0.00851355, 0.0349401 , 0.0346854 , 0.02510057, 0.02789748,\n          0.01807737, 0.00399827, 0.03858687, 0.00625978, 0.04284173],\n         [0.03329359, 0.01851361, 0.02300249, 0.00893552, 0.02797374,\n          0.00704761, 0.03586481, 0.02352679, 0.032483  , 0.04332578],\n         [0.03929847, 0.02267011, 0.0176017 , 0.01879289, 0.03611834,\n          0.03492691, 0.00083844, 0.02622012, 0.03828369, 0.02523276],\n         [0.01056316, 0.04972503, 0.00591751, 0.0068207 , 0.01503301,\n          0.01101399, 0.01583511, 0.03730742, 0.00603433, 0.01290766]],\n \n        [[0.0166581 , 0.03862909, 0.0361024 , 0.04036099, 0.00755537,\n          0.0293372 , 0.04685419, 0.01146455, 0.01628304, 0.02547259],\n         [0.04170443, 0.00777407, 0.01301534, 0.0244643 , 0.00850265,\n          0.00269446, 0.0084148 , 0.01581562, 0.0321689 , 0.00425057],\n         [0.01483479, 0.04318823, 0.02870348, 0.03161938, 0.01368423,\n          0.0050819 , 0.02865047, 0.00808151, 0.02107074, 0.00564638],\n         [0.00785901, 0.02947134, 0.0054091 , 0.03795815, 0.01702836,\n          0.01644456, 0.02641676, 0.03433629, 0.00130953, 0.03725034],\n         [0.04885339, 0.01271894, 0.02232116, 0.02859368, 0.00392827,\n          0.029167  , 0.02826202, 0.04346392, 0.04840693, 0.01687331],\n         [0.01515751, 0.01468797, 0.01756771, 0.01764944, 0.0289862 ,\n          0.04560875, 0.03748497, 0.04366092, 0.02831777, 0.00545305],\n         [0.0360167 , 0.0226516 , 0.03428043, 0.00581638, 0.01075681,\n          0.015826  , 0.02952883, 0.04251679, 0.04909121, 0.00010864],\n         [0.03228878, 0.04155992, 0.02898718, 0.04419049, 0.01756685,\n          0.0186231 , 0.03975404, 0.01599727, 0.02338454, 0.00214882],\n         [0.0485891 , 0.04256222, 0.03837604, 0.0250407 , 0.02310856,\n          0.03820034, 0.04763421, 0.04679049, 0.01035286, 0.02600919],\n         [0.02516395, 0.04106591, 0.01853354, 0.03958878, 0.03294401,\n          0.03699954, 0.04484257, 0.00378885, 0.00329868, 0.0200268 ]]],\n       dtype=float32)>,\n <tf.Variable 'mps_tensors_7:0' shape=(2, 10, 10) dtype=float32, numpy=\n array([[[0.02398819, 0.02311429, 0.03570152, 0.01336177, 0.01249584,\n          0.03337695, 0.00567442, 0.00150184, 0.02462565, 0.03891651],\n         [0.02234799, 0.04185233, 0.01289682, 0.04749709, 0.04972213,\n          0.04986582, 0.02866919, 0.02753767, 0.01110771, 0.00288099],\n         [0.00649561, 0.00514377, 0.03432915, 0.02109939, 0.00275196,\n          0.02839813, 0.01408477, 0.01729562, 0.01568248, 0.02520243],\n         [0.00848852, 0.00220555, 0.042272  , 0.04833731, 0.01300427,\n          0.02567798, 0.00847952, 0.02078345, 0.00689126, 0.02489262],\n         [0.01633309, 0.04663695, 0.04790559, 0.02156847, 0.02817884,\n          0.00796038, 0.02465029, 0.01746538, 0.04112567, 0.01466781],\n         [0.01691724, 0.00115268, 0.04100106, 0.02686184, 0.04831281,\n          0.04902347, 0.03373802, 0.01232575, 0.03558669, 0.01838823],\n         [0.00123175, 0.01203225, 0.0137114 , 0.00972489, 0.01874194,\n          0.00925733, 0.02979283, 0.01364984, 0.00497778, 0.01873271],\n         [0.01173781, 0.00793973, 0.03145115, 0.02026973, 0.040326  ,\n          0.0441062 , 0.02996766, 0.02758422, 0.03367217, 0.02126461],\n         [0.04089762, 0.03999154, 0.03145321, 0.00210076, 0.04786716,\n          0.00521094, 0.0227592 , 0.02157868, 0.04673732, 0.02980455],\n         [0.00601428, 0.04833784, 0.02486506, 0.03346498, 0.00988808,\n          0.00859516, 0.00876592, 0.00053958, 0.01734425, 0.04496499]],\n \n        [[0.02702007, 0.04823048, 0.02649094, 0.01857193, 0.0005034 ,\n          0.00164869, 0.04631491, 0.03456332, 0.02546838, 0.00765055],\n         [0.04983398, 0.03838887, 0.02128535, 0.00876732, 0.0140572 ,\n          0.01414395, 0.04275277, 0.03900607, 0.02955123, 0.03437707],\n         [0.03382393, 0.00039588, 0.02221131, 0.00512299, 0.0355505 ,\n          0.01244918, 0.03900948, 0.0448275 , 0.04440792, 0.03977267],\n         [0.04856116, 0.00946002, 0.00748833, 0.02205058, 0.01068455,\n          0.04127539, 0.00118286, 0.02860925, 0.03033229, 0.01776444],\n         [0.03749991, 0.02217858, 0.02117145, 0.03125128, 0.04821325,\n          0.01181665, 0.00635017, 0.01519282, 0.01467222, 0.01730468],\n         [0.02170113, 0.04053643, 0.01173387, 0.00214266, 0.03255736,\n          0.04123201, 0.0216201 , 0.03582431, 0.04979031, 0.00132944],\n         [0.0106679 , 0.0146118 , 0.01514006, 0.02452604, 0.00454246,\n          0.03884115, 0.02342151, 0.01972003, 0.03091613, 0.00901324],\n         [0.04506367, 0.03934598, 0.04839094, 0.02401561, 0.0275598 ,\n          0.02869688, 0.01783046, 0.04664771, 0.0082932 , 0.0090796 ],\n         [0.01422377, 0.04010464, 0.01162518, 0.03035234, 0.0048998 ,\n          0.02156743, 0.00062962, 0.00842039, 0.0150054 , 0.04949287],\n         [0.00853965, 0.0066685 , 0.01286961, 0.00390747, 0.00335706,\n          0.04238009, 0.01498702, 0.00960692, 0.04775407, 0.02356153]]],\n       dtype=float32)>,\n <tf.Variable 'mps_tensors_8:0' shape=(2, 10, 10) dtype=float32, numpy=\n array([[[0.03319133, 0.01141159, 0.01222239, 0.03716892, 0.0380781 ,\n          0.03400229, 0.01041095, 0.01681824, 0.00140194, 0.01821606],\n         [0.01633376, 0.008662  , 0.03875986, 0.04204834, 0.04488321,\n          0.03739705, 0.03155759, 0.02498143, 0.02678199, 0.03551213],\n         [0.03660237, 0.00969423, 0.0285994 , 0.03550381, 0.04166655,\n          0.01302648, 0.03984977, 0.03342545, 0.01784966, 0.03562564],\n         [0.00832531, 0.0481227 , 0.04923042, 0.00204411, 0.04822375,\n          0.04659386, 0.02094693, 0.03810832, 0.02428135, 0.02697064],\n         [0.02005259, 0.03464601, 0.00762909, 0.00636917, 0.02412588,\n          0.03474116, 0.03154136, 0.02606062, 0.02922582, 0.03326848],\n         [0.00363289, 0.02358741, 0.03287977, 0.04051894, 0.00419686,\n          0.00596564, 0.00866349, 0.00233734, 0.03537267, 0.00441621],\n         [0.03401027, 0.02319631, 0.00289053, 0.01656925, 0.03351321,\n          0.04591329, 0.02567377, 0.00532454, 0.03432878, 0.03317337],\n         [0.03105086, 0.03921898, 0.00619646, 0.01524068, 0.02547562,\n          0.01499532, 0.03147861, 0.04090483, 0.00720816, 0.00208566],\n         [0.04947014, 0.00899748, 0.03875814, 0.04691643, 0.00623047,\n          0.00441563, 0.04184733, 0.02289558, 0.04187451, 0.04623537],\n         [0.01864212, 0.04174761, 0.03465289, 0.03457467, 0.02850693,\n          0.00793228, 0.03169122, 0.00790804, 0.00490859, 0.04101337]],\n \n        [[0.04046204, 0.0476908 , 0.04710201, 0.03570098, 0.04828538,\n          0.02146916, 0.01569736, 0.01906756, 0.02821271, 0.01912167],\n         [0.00133592, 0.02802749, 0.01223455, 0.03772997, 0.01867896,\n          0.03370935, 0.03112601, 0.02948191, 0.03007667, 0.00044532],\n         [0.03606098, 0.02204054, 0.02986443, 0.00019461, 0.03075572,\n          0.0441115 , 0.01988621, 0.04558148, 0.04365667, 0.02272253],\n         [0.01139298, 0.0258958 , 0.01352495, 0.00189418, 0.02478795,\n          0.01029411, 0.02791782, 0.03939716, 0.02408648, 0.00746555],\n         [0.00072528, 0.02729238, 0.00069717, 0.02633539, 0.00443574,\n          0.02702582, 0.03341575, 0.01080045, 0.03418396, 0.00209851],\n         [0.01121629, 0.04892528, 0.03292421, 0.043915  , 0.01092625,\n          0.00707791, 0.02553147, 0.0082831 , 0.03465099, 0.04547762],\n         [0.01903774, 0.03914234, 0.02605683, 0.01226513, 0.02108507,\n          0.00961376, 0.04694514, 0.04752129, 0.0102762 , 0.0117685 ],\n         [0.03391127, 0.02379461, 0.02413572, 0.04576355, 0.03801521,\n          0.00831611, 0.01774482, 0.03880675, 0.0175607 , 0.03545804],\n         [0.00083095, 0.02082144, 0.02815405, 0.00449041, 0.04236045,\n          0.01793282, 0.01958882, 0.0364241 , 0.03714664, 0.01020873],\n         [0.00070458, 0.01250632, 0.01176081, 0.03091284, 0.00646   ,\n          0.04096919, 0.01839115, 0.03426421, 0.01488351, 0.03336645]]],\n       dtype=float32)>,\n <tf.Variable 'mps_tensors_9:0' shape=(2, 10) dtype=float32, numpy=\n array([[0.03086761, 0.04112537, 0.00576125, 0.02377061, 0.01514006,\n         0.0206299 , 0.03306402, 0.01652939, 0.01072883, 0.04340049],\n        [0.01919627, 0.02322648, 0.01963698, 0.02551705, 0.03802855,\n         0.04100472, 0.04644005, 0.01292402, 0.03149156, 0.02941298]],\n       dtype=float32)>]"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "quantum_dmrg_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "quantum_dmrg_model.layers[0].non_trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosx = np.random.uniform(size=10)\n",
    "\n",
    "inputs = np.array([np.array([cosx, np.sqrt(1-cosx*cosx)]).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[4.5197291e-07, 4.2527077e-07, 4.5495318e-07]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "output = quantum_dmrg_model.predict(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[TensorShape([2, 10]), TensorShape([2, 10, 10]), TensorShape([2, 10, 10])]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "[quantum_dmrg_model.layers[0].mps_tensors[i].shape for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nquantum_dmrg_layer_1 (Quantu (None, 3)                 0         \n=================================================================\nTotal params: 0\nTrainable params: 0\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "quantum_dmrg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}